{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import  confusionTable_extractFeature as CTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "POS = 1\n",
    "NEG = -1\n",
    "UNK = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROCESSCNT = 2\n",
    "MULTIPROCESS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "with Pool(processes=PROCESSCNT) as pool:\n",
    "    for x in range(5):\n",
    "        r = pool.apply_async(lambda i:i*2, (x, ))\n",
    "        results.append(r)\n",
    "    for r in results:\n",
    "        r.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<multiprocessing.pool.ApplyResult at 0x7f1ec5543a90>,\n",
       " <multiprocessing.pool.ApplyResult at 0x7f1ec5543a20>,\n",
       " <multiprocessing.pool.ApplyResult at 0x7f1ec5543860>,\n",
       " <multiprocessing.pool.ApplyResult at 0x7f1ec55430f0>,\n",
       " <multiprocessing.pool.ApplyResult at 0x7f1ec55435c0>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ttt = results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ttt.wait?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract(bigDict):\n",
    "    '''Extract (feature/label) from filename\n",
    "    Args:\n",
    "        bigDict (nested dict): the dict of feature (*.pkl) from confusionTable_extractFeature\n",
    "    Return:\n",
    "        train_feature (np.array): feature array\n",
    "        train_label (np.array): the label of feature \n",
    "            (1 for positive, 2 for negative )\n",
    "    '''\n",
    "    \n",
    "    # Initial \n",
    "    label = list()\n",
    "    feature = list()\n",
    "\n",
    "    for error_ch, (cands_val) in bigDict.items():\n",
    "        # two situation for error: (error-pair) or (higher-score)\n",
    "        for cand, (score, log) in cands_val.items():                        \n",
    "            feature.append(log[:-2])\n",
    "            \n",
    "            \n",
    "            if log[-2] != 0:\n",
    "                label.append(POS)\n",
    "            else:\n",
    "                label.append(UNK)\n",
    "    \n",
    "    # Combine\n",
    "    train_feature = np.asarray(feature, dtype='float')            \n",
    "    tmp_label = np.asarray(label, dtype='int')\n",
    "    pos = np.where(tmp_label == POS )[0]\n",
    "    neg = np.where(tmp_label == UNK )[0]\n",
    "    train_label = {POS:pos, UNK:neg}        \n",
    "\n",
    "    print('The number of sample = {}'.format(train_feature.shape))\n",
    "    print('Positive case (candidate) = {}'.format(len(train_label[POS])))\n",
    "    print('Negative case (uncandidate) = {}'.format(len(train_label[UNK])))\n",
    "    \n",
    "    return (train_feature, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(data, method):\n",
    "    '''Preprocessing of feature\n",
    "    Args:\n",
    "        data (np.array): feature \n",
    "        method (str): 'normal'-normalization // 'standard'-standardization\n",
    "    Return:\n",
    "        new_data (np.array): after preprocessing \n",
    "        pre (scikit.preprocess): transform model for feature     \n",
    "    '''\n",
    "    if method == 'normal':\n",
    "        pre = Normalizer().fit(data)\n",
    "        new_data = pre.transform(data)\n",
    "    elif method == 'standard':\n",
    "        pre = Normalizer().fit(data)\n",
    "        new_data = pre.transform(data)\n",
    "    else:\n",
    "        print('Unknown method')\n",
    "        sys.exit(0)\n",
    "    \n",
    "    return (new_data, pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rn = RN(new_feature, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rn.runrun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RN:\n",
    "    def __init__(self, feature, label):\n",
    "        nbf_idx = np.concatenate((label[POS],label[UNK]))\n",
    "        nbf_label = np.concatenate(\n",
    "            (np.full(len(label[POS]), POS, dtype=int)\n",
    "             , np.full(len(label[UNK]), UNK, dtype=int)))\n",
    "        nbf_feature = feature[nbf_idx]\n",
    "        self.nbf = GaussianNB().fit(nbf_feature, nbf_label)\n",
    "        self.chunk = [(idx, feature[idx]) for idx in label[UNK]]\n",
    "    \n",
    "    def runrun(self):\n",
    "        \n",
    "        if MULTIPROCESS:\n",
    "            with Pool(processes=PROCESSCNT) as pool:\n",
    "                self.rn_neg = pool.map(self.rnBatch, self.chunk)\n",
    "            \n",
    "    \n",
    "    def rnBatch(self, chunk):\n",
    "        if self.nbf.predict(chunk[1].reshape(1,-1)) == UNK:\n",
    "            return chunk[0]\n",
    "        else:\n",
    "            return -1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rnSelect(feature, label):\n",
    "    def rnBatch(chunk):\n",
    "        if nbf.predict(chunk[1].reshape(1,-1)) == UNK:\n",
    "            return chunk[0]\n",
    "        else:\n",
    "            return -1\n",
    "        \n",
    "    nbf_idx = np.concatenate((label[POS],label[UNK]))\n",
    "    nbf_label = np.concatenate(\n",
    "        (np.full(len(label[POS]), POS, dtype=int)\n",
    "         , np.full(len(label[UNK]), UNK, dtype=int)))\n",
    "    nbf_feature = feature[nbf_idx]\n",
    "    nbf = GaussianNB().fit(nbf_feature, nbf_label)\n",
    "\n",
    "#     print('Start RN step select')\n",
    "    chunk = [(idx, feature[idx]) for idx in label[UNK]]\n",
    "    \n",
    "    if MULTIPROCESS:\n",
    "        with Pool(processes=PROCESSCNT) as pool:\n",
    "            rn_neg = pool.map(rnBatch, chunk)\n",
    "    else:\n",
    "        rn_neg = [rnBatch(c) for c in chunk]\n",
    "        \n",
    "        \n",
    "    label[NEG] = np.where(np.asarray(rn_neg) != -1)[0]\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'rnSelect.<locals>.rnBatch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-dd39bee34e62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnSelect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-a7c8642e9883>\u001b[0m in \u001b[0;36mrnSelect\u001b[0;34m(feature, label)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mMULTIPROCESS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPROCESSCNT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mrn_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mrn_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrnBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kiwi/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         '''\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kiwi/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kiwi/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_handle_tasks\u001b[0;34m(taskqueue, put, outqueue, pool, cache)\u001b[0m\n\u001b[1;32m    383\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                         \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kiwi/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_writable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kiwi/anaconda3/lib/python3.6/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'rnSelect.<locals>.rnBatch'"
     ]
    }
   ],
   "source": [
    "l = rnSelect(new_feature, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_svm(feature, label, train_cnt, test_cnt=0, cross_validation=False):\n",
    "    '''Train SVM model from feature\n",
    "    Args:\n",
    "        feature (np.array): feature array\n",
    "        label (np.array): the label of feature \n",
    "        train_cnt (int): the number of training samples \n",
    "        test_cnt (int): (default=samples-train_cnt) the number of testing samples\n",
    "    Return:\n",
    "        xxx    \n",
    "    '''\n",
    "    \n",
    "    assert train_cnt < len(label[POS]), 'Train count must less than positive samples'\n",
    "    \n",
    "    # If test_cnt not declare, use all the remain set as test set    \n",
    "    if train_cnt==0:\n",
    "        assert False, 'sample count cannot be zero'\n",
    "        \n",
    "    if test_cnt==0:\n",
    "        test_cnt = len(label[POS]) - train_cnt\n",
    "        \n",
    "    # Picke feature/label to train & test set    \n",
    "    np.random.shuffle(label[POS])\n",
    "    np.random.shuffle(label[NEG])\n",
    "\n",
    "    train_idx = np.concatenate(\n",
    "        (label[POS][:train_cnt],\n",
    "         label[NEG][:train_cnt]))\n",
    "    train_label = np.concatenate(\n",
    "        (np.full(train_cnt, POS, dtype=int), np.full(train_cnt, NEG, dtype=int)))\n",
    "    train_feature = feature[train_idx]\n",
    "\n",
    "    test_idx = np.concatenate(\n",
    "        (label[POS][train_cnt:train_cnt+test_cnt], \n",
    "         label[NEG][train_cnt:train_cnt+test_cnt]))\n",
    "    test_label = np.concatenate(\n",
    "        (np.full(test_cnt, POS, dtype=int), np.full(test_cnt, NEG, dtype=int)))\n",
    "    test_feature = feature[test_idx]\n",
    "\n",
    "    # Training \n",
    "    clf = svm.SVC(kernel='rbf', probability=True)\n",
    "    clf.fit(train_feature,train_label)\n",
    "    \n",
    "    # Testing \n",
    "    accuracy = clf.score(test_feature, test_label)\n",
    "    pos_acc = clf.score(test_feature[:test_cnt], test_label[:test_cnt])\n",
    "    print('Accuracy ({}/{}): {}'.format(test_cnt, len(test_label), accuracy))\n",
    "    print('Positive Accuracy ({}): {}'.format(test_cnt, pos_acc))\n",
    "    \n",
    "#     output = [accuracy, train_cnt, test_cnt*2]\n",
    "#     return output\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create(clf, bigDict, pre_filter, threshold):\n",
    "    '''Construct basic NCM\n",
    "    \n",
    "    '''\n",
    "    confusion = defaultdict(dict)\n",
    "    c_t, c_tf, sk = 0,0,0\n",
    "    \n",
    "    idx =0\n",
    "    for ch, cands in bigDict.items():\n",
    "#         if idx>5:break\n",
    "#         idx+=1\n",
    "#         print(ch)\n",
    "        for ca, (score,log) in cands.items():            \n",
    "            tmp = pre_filter.transform(np.asarray(log[:-2]).reshape(1,-1))\n",
    "            f = clf.predict_proba(tmp).tolist()[0]            \n",
    "            \n",
    "            # Known confusion pair\n",
    "            if log[-2] != 0:\n",
    "                c_t += 1\n",
    "                ###########\n",
    "                # MAY have bad score\n",
    "                ###########\n",
    "                \n",
    "            # Unknown confusion pair but predict \n",
    "            elif f[0] > f[1] and f[0] > threshold:\n",
    "                c_tf += 1\n",
    "            else:\n",
    "                sk += 1\n",
    "                continue\n",
    "            \n",
    "            confusion[ch][ca] = f[0]                        \n",
    "        \n",
    "    print('Original Pair: {}\\tNew Pair: {}\\tSkip Pair:{}'.format(c_t, c_tf, sk))\n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def info(confusion):\n",
    "    '''Get basic information about NCM \n",
    "    \n",
    "    '''\n",
    "    total_error = len(confusion)\n",
    "    cands = [(ch, len(cand)) for (ch, cand) in \n",
    "        sorted(confusion.items(), key= lambda x:len(x[1]), reverse=True)]\n",
    "\n",
    "    sum_cands = sum(cnt for _, cnt in cands)\n",
    "    max_cands = max(cnt for _, cnt in cands)\n",
    "    min_cands = min(cnt for _, cnt in cands)\n",
    "    mean_cands = sum_cands/total_error\n",
    "    \n",
    "    if total_error%2 == 0:\n",
    "        mid_cands = cands[total_error//2]\n",
    "    else:\n",
    "        mid_cands = cands[(total_error+1)//2]\n",
    "    \n",
    "    print('Total_error: {}\\nSum_cands: {}'.format(total_error, sum_cands))\n",
    "    print('Max_cands: {}\\nMin_cands: {}'.format(max_cands, min_cands))\n",
    "    print('Mean_cands: {:.2f}\\nMid_cands: {}'.format(mean_cands, mid_cands))\n",
    "    print('Top 20 cands:\\n {}'.format(cands[:20]))\n",
    "    \n",
    "    plt.plot([cnt for _, cnt in cands])\n",
    "    plt.xlabel('index')\n",
    "    plt.ylabel('candidates number')\n",
    "    fig = plt.gcf()\n",
    "    plt.show()\n",
    "    fig.savefig('./confusionTable/confu_info.png',dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outputPKL(confusion, ncm_correct, pkl_file):\n",
    "    '''Assign local probability and output to NCM file\n",
    "    '''\n",
    "    output = defaultdict(dict)\n",
    "    \n",
    "    for ch, cands in confusion.items():\n",
    "        total_cand_val = sum(cands.values())*(1-ncm_correct) + ncm_correct\n",
    "        output[ch] = {ca:(p*(1-ncm_correct))/total_cand_val for ca,p in cands.items()}\n",
    "        output[ch][ch] = ncm_correct/total_cand_val        \n",
    "    \n",
    "    with open('./confusionTable/{}'.format(pkl_file), 'wb') as fp:\n",
    "        pickle.dump(output, fp)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    feature_file = './confusionTable/feature.pkl'\n",
    "    output_file = './confusionTable/confu_{}'.format\n",
    "    ncm_correct = 0.95\n",
    "        \n",
    "    with open(feature_file, 'rb') as fp:\n",
    "        dataset = pickle.load(fp)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of sample = (2592820, 10)\n",
      "Positive case (candidate) = 9357\n",
      "Negative case (uncandidate) = 2583463\n"
     ]
    }
   ],
   "source": [
    "feature,label = extract(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(feature, pre) = preprocess(feature, 'normal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = rnSelect(feature, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature,label = extract(dataset)\n",
    "\n",
    "(new_feature, pre) = preTrain(feature, 'normal')\n",
    "\n",
    "clf = train(new_feature, label, 4000)\n",
    "\n",
    "confu_raw = create(clf, dataset, pre, 0.85)\n",
    "\n",
    "info(confu_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confu = outputPKL(confu_raw, ncm_correct, output_file('xxx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
