{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batchProcessing(batch, TOKEN):\n",
    "    lst = batch[0].strip().split('\\t')\n",
    "    trainSet = int(lst[0].split()[-1])    \n",
    "    cost, gamma = [float(i.split()[-1]) for i in lst[1:]]\n",
    "    \n",
    "    SKIP = 5 if TOKEN[-1]=='T' else 0        \n",
    "    acc = float(batch[SKIP+1].split()[-1])\n",
    "    posacc = float(batch[SKIP+2].split()[-1])\n",
    "    total_error = int(batch[SKIP+3].strip().split()[-1])\n",
    "    sum_cands = int(batch[SKIP+4].strip().split()[-1])\n",
    "    max_cands = int(batch[SKIP+5].strip().split()[-1])\n",
    "    min_cands = int(batch[SKIP+6].strip().split()[-1])\n",
    "    mean_cands = float(batch[SKIP+7].strip().split()[-1])\n",
    "    mid_cands = ''.join(batch[SKIP+8].strip().split()[1:])\n",
    "    top10_cands = batch[SKIP+10].strip()\n",
    "    confu_info = {'total':total_error, 'sum':sum_cands, 'max':max_cands, 'min':min_cands, \n",
    "                  'mean':mean_cands, 'mid':mid_cands, 'top10':top10_cands}\n",
    "    \n",
    "    pkl_file = 'cofnu_{}_{}_{}_{}_{}_{}.pkl'.format    \n",
    "    ncm_pars = [0.9995, 0.99995, 0.999995, 0.9999995]\n",
    "    par_str = [str(trainSet), str(cost)[2:] if cost<1 else str(cost), str(gamma)[2:]]\n",
    "    pkl_files = [pkl_file(TOKEN, TOKEN, par_str[0], par_str[1], par_str[2], str(ncm_set)[2:])\n",
    "                 for ncm_set in ncm_pars]\n",
    "    \n",
    "    batch_info = {'acc':[acc,posacc], 'confu':confu_info, 'pkl':pkl_files}\n",
    "    \n",
    "    return (tuple((trainSet, cost, gamma)), batch_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sectionProcessing(file):\n",
    "    with open(file, 'r', encoding='utf8') as fp:\n",
    "        seqs = fp.readlines()   \n",
    "        \n",
    "    lst = seqs[5].split('\\t')\n",
    "    pre_str = 'preT' if lst[0].split()[1]=='True' else 'preF'\n",
    "    nb_str = 'nbT' if lst[1].split()[1]=='True' else 'nbF'\n",
    "    TOKEN = pre_str+nb_str\n",
    "\n",
    "    START = 6\n",
    "    section = dict()\n",
    "\n",
    "    for STOP, line in enumerate(seqs[START:], START):\n",
    "        if 'Output' in line:\n",
    "            if STOP - START > 1:   \n",
    "                key, value = batchProcessing(seqs[START:STOP], TOKEN)\n",
    "                section[key] = value\n",
    "            START = STOP+1  \n",
    "    return (section, TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def winnerSelect(section):\n",
    "    train_cntpar = [1000, 2000, 3000, 4000]\n",
    "    compare_mat = defaultdict(lambda :dict())\n",
    "    for key, content in section.items():\n",
    "        for cnt in train_cntpar:\n",
    "            if cnt in key:\n",
    "                compare_mat[cnt][key] = content\n",
    "                break\n",
    "\n",
    "    winner_mat = dict()\n",
    "    for cnt in train_cntpar:\n",
    "        winner_mat[cnt] = sorted(compare_mat[cnt].items(), key= lambda x:sum(x[1]['acc']), reverse=True)[0]\n",
    "    return winner_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATAROOT = './confusionTable/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for a,b,c in os.walk(DATAROOT):        \n",
    "    if not b:\n",
    "        continue        \n",
    "    filelist = [DATAROOT+f for f in c if 'pre' in f and 'swp' not in f]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./confusionTable/preFnbT.txt\n",
      "./confusionTable/preTnbF.txt\n",
      "./confusionTable/preTnbT.txt\n",
      "./confusionTable/preFnbF.txt\n"
     ]
    }
   ],
   "source": [
    "result = dict()\n",
    "for file in filelist:\n",
    "    print(file)\n",
    "    result[file] = sectionProcessing(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultfilename = DATAROOT+'acc_confu.csv'\n",
    "with open(resultfilename, 'w', encoding='utf8') as wp:\n",
    "    for section,TOKEN in result.values():\n",
    "        for key, value in section.items():\n",
    "            line = '{},{k[0]},{k[1]},{k[2]},{a[0]:.4f},{a[1]:.4f},{con[mean]},{con[max]}\\n'.format(TOKEN, k=key, a=value['acc'], con=value['confu'])\n",
    "            wp.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "winnerfilename = DATAROOT+'acc_winner.csv'\n",
    "with open(winnerfilename, 'w', encoding='utf8') as wp:\n",
    "    for _,(section, TOKEN) in result.items():\n",
    "        section_winner = winnerSelect(section)\n",
    "        for cnt, batch in section_winner.items():\n",
    "            line = '{},{k[0]},{k[1]},{k[2]},{a[0]:.4f},{a[1]:.4f},{con[mean]},{con[max]}\\n'.format(\n",
    "                TOKEN, k=batch[0], a=batch[1]['acc'], con=batch[1]['confu'])\n",
    "            wp.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
