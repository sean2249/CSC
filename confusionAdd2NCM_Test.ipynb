{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading language model /home/kiwi/udn_data/training_confusion/sinica.corpus.seg.char.lm ...\n",
      "Loading channel model /home/kiwi/udn_data/training_confusion/channelModel.pkl ...\n",
      "Loading Preprocess_RuleBased model ./extractUDN_prepost/all.csv ...\n"
     ]
    }
   ],
   "source": [
    "import charSpellingCheck as CSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testData_name = './test_15/SIGHAN15_CSC_TestInput.txt'\n",
    "testGroundTruth_name = './test_15/SIGHAN15_CSC_TestTruth.txt'\n",
    "systemTruth_name = './test_15/re_newLM15_2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output_name ='./confusionAdd/test_{}.csv'.format\n",
    "output_name ='./confusionAdd/confusionSet_{}.pkl'.format\n",
    "\n",
    "log_file = 'log.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toDict(lst):\n",
    "    out = dict()\n",
    "    if len(lst)%2==0:\n",
    "        for idx in range(0, len(lst), 2):\n",
    "            out[lst[idx]] = lst[idx+1]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def task(gt_dict,st_dict,seq):\n",
    "    # Original character\n",
    "    for error_idx, corr_ch in gt_dict.items():\n",
    "        error_ch = seq[int(error_idx)-1]\n",
    "        sys_ch = st_dict.get(error_idx,'x')\n",
    "\n",
    "        if corr_ch != sys_ch or error_idx not in st_dict:\n",
    "            check = [i for i,_ in CSC.debug_ncm(error_ch) if i==corr_ch]\n",
    "            if len(check)!=0: # \n",
    "                continue \n",
    "\n",
    "            total += 1\n",
    "            if CSC.ncm.table.get(error_ch,None):\n",
    "                CSC.debug_ncm(error_ch, corr_ch, ncm_insert_val)\n",
    "            else:\n",
    "                CSC.ncm.table[error_ch] = {corr_ch:ncm_insert_val, error_ch:0.95}\n",
    "\n",
    "            new = CSC.batch(seq)\n",
    "            new_st = dict((idx,err) for idx, err in new)\n",
    "\n",
    "            row_write = [dataID,0,str(error_idx),error_ch,corr_ch,sys_ch,seq]\n",
    "            if new_st.get(error_idx, None) == corr_ch:\n",
    "                good += 1\n",
    "                row_write[1] = 1\n",
    "            CSC.ncm.table[error_ch].pop(corr_ch, None)\n",
    "    return row_write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Test add problem\n",
    "'''\n",
    "\n",
    "ncm_insert_vals = [0.005,0.01,0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95]\n",
    "for ncm_insert_val in ncm_insert_vals:\n",
    "    with open(testData_name, 'r', encoding='utf8') as tdp,\\\n",
    "    open(testGroundTruth_name, 'r', encoding='utf8') as tgtp,\\\n",
    "    open(systemTruth_name, 'r', encoding='utf8') as stp,\\\n",
    "    open(output_name(str(ncm_insert_val)[2:]), 'w', newline='',encoding='utf8') as ws:\n",
    "\n",
    "        wp = csv.writer(ws)\n",
    "        wp.writerow(['DataID','Label','Position','Error','Groud Truth','Original System Result','Sequence'])\n",
    "\n",
    "\n",
    "        good, total = 0, 0\n",
    "        for idx in trange(1100, unit='seq'):\n",
    "            \n",
    "            if idx>5: break\n",
    "            \n",
    "            td_line = tdp.readline().strip('\\n')\n",
    "\n",
    "            dataID = td_line[:(td_line.find(')'))+1]\n",
    "            seq = td_line[(td_line.find(')')+2):]\n",
    "\n",
    "#             tgt_line = tgtp.readline()\n",
    "#             st_line  = stp.readline()\n",
    "            gt = tgtp.readline().strip().split(', ')[1:]\n",
    "            st = stp.readline().strip().split(', ')[1:]\n",
    "\n",
    "\n",
    "            if gt == st:\n",
    "                continue\n",
    "\n",
    "            gt_dict = toDict(gt)\n",
    "            st_dict = toDict(st)\n",
    "\n",
    "            # Original character\n",
    "            for error_idx, corr_ch in gt_dict.items():\n",
    "                \n",
    "                '''\n",
    "                error_idx, error_ch\n",
    "                corr_ch, sys_ch\n",
    "                \n",
    "                st_dict\n",
    "                \n",
    "                ncm_insert_val\n",
    "                \n",
    "                dataID, seq\n",
    "                good, total\n",
    "                '''\n",
    "                \n",
    "                error_ch = seq[int(error_idx)-1]\n",
    "                sys_ch = st_dict.get(error_idx,'x')\n",
    "                \n",
    "                if corr_ch != sys_ch or error_idx not in st_dict:\n",
    "                    check = [i for i,_ in CSC.debug_ncm(error_ch) if i==corr_ch]\n",
    "                    if len(check)!=0: # \n",
    "                        continue \n",
    "\n",
    "                    total += 1\n",
    "                    if CSC.ncm.table.get(error_ch,None):\n",
    "                        CSC.debug_ncm(error_ch, corr_ch, ncm_insert_val)\n",
    "                    else:\n",
    "                        CSC.ncm.table[error_ch] = {corr_ch:ncm_insert_val, error_ch:0.95}\n",
    "\n",
    "                    new = CSC.batch(seq)\n",
    "                    new_st = dict((idx,err) for idx, err in new)\n",
    "\n",
    "                    row_write = [dataID,0,str(error_idx),error_ch,corr_ch,sys_ch,seq]\n",
    "                    if new_st.get(error_idx, None) == corr_ch:\n",
    "                        good += 1\n",
    "                        row_write[1] = 1\n",
    "                    CSC.ncm.table[error_ch].pop(corr_ch, None)\n",
    "\n",
    "                    wp.writerow(row_write)\n",
    "\n",
    "\n",
    "    print('Done.')\n",
    "    with open(log_file, 'a', encoding='utf8') as fp:\n",
    "        fp.write('{}\\t{}\\t{}\\n'.format(ncm_insert_val,good,total))\n",
    "    print(good, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "backup = copy.deepcopy(CSC.ncm.table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./confusionAdd/confusionSet_005.pkl\n",
      "0.005 Done.\n",
      "./confusionAdd/confusionSet_01.pkl\n",
      "0.01 Done.\n",
      "./confusionAdd/confusionSet_05.pkl\n",
      "0.05 Done.\n",
      "./confusionAdd/confusionSet_15.pkl\n",
      "0.15 Done.\n",
      "./confusionAdd/confusionSet_25.pkl\n",
      "0.25 Done.\n",
      "./confusionAdd/confusionSet_35.pkl\n",
      "0.35 Done.\n",
      "./confusionAdd/confusionSet_45.pkl\n",
      "0.45 Done.\n",
      "./confusionAdd/confusionSet_55.pkl\n",
      "0.55 Done.\n",
      "./confusionAdd/confusionSet_65.pkl\n",
      "0.65 Done.\n",
      "./confusionAdd/confusionSet_75.pkl\n",
      "0.75 Done.\n",
      "./confusionAdd/confusionSet_85.pkl\n",
      "0.85 Done.\n",
      "./confusionAdd/confusionSet_95.pkl\n",
      "0.95 Done.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Create confusion set\n",
    "'''\n",
    "\n",
    "ncm_insert_vals = [0.005,0.01,0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95]\n",
    "# ncm_insert_vals = [0.005]\n",
    "for ncm_insert_val in ncm_insert_vals:\n",
    "    with open(testData_name, 'r', encoding='utf8') as tdp,\\\n",
    "    open(testGroundTruth_name, 'r', encoding='utf8') as tgtp,\\\n",
    "    open(systemTruth_name, 'r', encoding='utf8') as stp,\\\n",
    "    open(output_name(str(ncm_insert_val)[2:]), 'w', newline='',encoding='utf8') as ws:\n",
    "\n",
    "    # open(output_name, 'w', encoding='utf8o') as wp:\n",
    "\n",
    "        wp = csv.writer(ws)\n",
    "        wp.writerow(['DataID','Label','Position','Error','Groud Truth','Original System Result','Sequence'])\n",
    "    #     row_write = [dataID,0,str(error_idx),error_ch,corr_ch,sys_ch,seq]\n",
    "\n",
    "\n",
    "        good, total = 0, 0\n",
    "        for idx in range(1100):\n",
    "            \n",
    "#             if idx>5: break\n",
    "            \n",
    "            td_line = tdp.readline().strip('\\n')\n",
    "\n",
    "            dataID = td_line[:(td_line.find(')'))+1]\n",
    "            seq = td_line[(td_line.find(')')+2):]\n",
    "\n",
    "#             tgt_line = tgtp.readline()\n",
    "#             st_line  = stp.readline()\n",
    "            gt = tgtp.readline().strip().split(', ')[1:]\n",
    "            st = stp.readline().strip().split(', ')[1:]\n",
    "\n",
    "\n",
    "            if gt == st:\n",
    "                continue\n",
    "\n",
    "            gt_dict = toDict(gt)\n",
    "            st_dict = toDict(st)\n",
    "\n",
    "            # Original character\n",
    "            for error_idx, corr_ch in gt_dict.items():\n",
    "                \n",
    "                '''\n",
    "                error_idx, error_ch\n",
    "                corr_ch, sys_ch\n",
    "                \n",
    "                st_dict\n",
    "                \n",
    "                ncm_insert_val\n",
    "                \n",
    "                dataID, seq\n",
    "                good, total\n",
    "                '''\n",
    "                \n",
    "                error_ch = seq[int(error_idx)-1]\n",
    "                sys_ch = st_dict.get(error_idx,'x')\n",
    "                \n",
    "                if corr_ch != sys_ch or error_idx not in st_dict:\n",
    "                    check = [i for i,_ in CSC.debug_ncm(error_ch) if i==corr_ch]\n",
    "                    if len(check)!=0: # \n",
    "                        continue \n",
    "\n",
    "                    total += 1\n",
    "                    if CSC.ncm.table.get(error_ch,None):\n",
    "                        CSC.debug_ncm(error_ch, corr_ch, ncm_insert_val)\n",
    "                    else:\n",
    "                        CSC.ncm.table[error_ch] = {corr_ch:ncm_insert_val, error_ch:0.95}\n",
    "\n",
    "                    \n",
    "    \n",
    "    print(output_name(str(ncm_insert_val)[2:]))\n",
    "    with open(output_name(str(ncm_insert_val)[2:]), 'wb') as fp:\n",
    "        pickle.dump(CSC.ncm.table, fp)\n",
    "    CSC.ncm.table = copy.deepcopy(backup)\n",
    "\n",
    "    print(ncm_insert_val, 'Done.')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     with open(log_file, 'a', encoding='utf8') as fp:\n",
    "#         fp.write('{}\\t{}\\t{}\\n'.format(ncm_insert_val,good,total))\n",
    "#     print(good, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# tmp = pd.DataFrame.from_csv('confusionAdd_utf8.csv')\n",
    "# special = tmp[tmp['Label']==0]\n",
    "# special_case = special.loc[:,'Sequence']\n",
    "\n",
    "# tt = special.sample(1)\n",
    "# tt\n",
    "\n",
    "# outputAll.to_csv('./zzz/output.csv')\n",
    "\n",
    "# outputAll = outputAll.append(tt)\n",
    "# outputAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./confusionAdd/confusionSet_-05.pkl','rb') as fp:\n",
    "    bigDict = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_dict = defaultdict(dict)\n",
    "for ch, d in bigDict.items():\n",
    "    prob = 1/len(d)    \n",
    "    out_dict[ch] = {cand:prob for cand in d.keys()}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./confusionAdd/channelModel_same.pkl', 'wb') as fp:\n",
    "    pickle.dump(out_dict, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
