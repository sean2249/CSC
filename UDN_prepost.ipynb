{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outputprepost(ptable, select_col):\n",
    "    def speDataframe(_gg):\n",
    "        _ggS = _gg.size()\n",
    "        _ggDF = pd.DataFrame(_ggS,columns=['count'])\n",
    "        _ggDF_sort = _ggDF.sort_values('count', ascending=False)\n",
    "        return _ggDF_sort\n",
    "        \n",
    "    output = ptable.groupby(select_col)\n",
    "    return speDataframe(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_prepost(input_filename, groundTruth_filename, kick_ptn='', specialSelect=False):\n",
    "    tmpdict = {'pre':[],'post':[],'corr':[],'error':[],'pre2':[],'post2':[]}\n",
    "    KICKPTN = re.compile(kick_ptn)\n",
    "\n",
    "    with open(input_filename, 'r', encoding='utf8') as ip, \\\n",
    "        open(groundTruth_filename, 'r', encoding='utf8') as gtp:\n",
    "        for line_idx, (seq_line, gt_line) in enumerate(zip(ip, gtp)):\n",
    "            seqID, seq = seq_line.strip('\\n').split('|||')\n",
    "            # ^M case \n",
    "            if len(seq) == 1:\n",
    "                seq = ip.readline().strip('\\n')                    \n",
    "            \n",
    "            gtlst = gt_line.strip('\\n').split('|||')\n",
    "            gtID, gt_info = gtlst[0], gtlst[1:]\n",
    "\n",
    "            if seqID != gtID:\n",
    "                print(seq_line, gt_line)\n",
    "                break\n",
    "\n",
    "            for idx, corr_ch in zip(gt_info[::2], gt_info[1::2]):\n",
    "                error_idx = int(idx)-1\n",
    "                try:\n",
    "                    pre2_ch  = str(seq[error_idx-2]) if error_idx-2 >= 0 else 'NAN'\n",
    "                    pre_ch   = str(seq[error_idx-1]) if error_idx-1 >= 0 else 'NAN'\n",
    "                    error_ch = seq[error_idx]            \n",
    "                    post_ch  = str(seq[error_idx+1]) if error_idx+1 < len(seq) else 'NAN'\n",
    "                    post2_ch = str(seq[error_idx+2]) if error_idx+2 < len(seq) else 'NAN'\n",
    "                except:\n",
    "                    print(line_idx, seq, error_idx)                   \n",
    "                    \n",
    "                # Same fix\n",
    "                if error_ch == corr_ch:\n",
    "                    print('Same on {}: {}'.format(seqId, error_ch))\n",
    "                    continue\n",
    "                    \n",
    "                # Remove NAN case\n",
    "                if pre_ch == 'NAN' or pre2_ch == 'NAN'\\\n",
    "                    or post_ch == 'NAN' or post2_ch == 'NAN'\\\n",
    "                    or error_ch == 'NAN' or corr_ch == 'NAN':\n",
    "                        continue\n",
    "                \n",
    "                # KICK pattern \n",
    "                if KICKPTN.search(error_ch) or KICKPTN.search(corr_ch):\n",
    "                    ptnflag = False if kick_ptn == '' else True                    \n",
    "                else:\n",
    "                    ptnflag = False\n",
    "                \n",
    "                if not(specialSelect ^ ptnflag):\n",
    "                    tmpdict['pre2'].append(pre2_ch)\n",
    "                    tmpdict['pre'].append(pre_ch)\n",
    "                    tmpdict['post'].append(post_ch)\n",
    "                    tmpdict['post2'].append(post2_ch)\n",
    "                    tmpdict['corr'].append(corr_ch)\n",
    "                    tmpdict['error'].append(error_ch)\n",
    "\n",
    "        pTable = pd.DataFrame(tmpdict)        \n",
    "        print('= Processing {} sequences'.format(line_idx))\n",
    "        print('= Processing {} pairs'.format(len(pTable)))\n",
    "        print('Done.')\n",
    "        \n",
    "        return (pTable, (line_idx, len(pTable)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(input_filename, groundTruth_filename, kick_ptn, special_select, case_token):\n",
    "    case_folder = './extractUDN_new/{}'.format(case_token)\n",
    "    print('File output to {}'.format(case_folder))\n",
    "    if not os.path.isdir(case_folder):\n",
    "        os.mkdir(case_folder)\n",
    "    \n",
    "    df, df_info = extract_prepost(input_filename, groundTruth_filename, kick_ptn, special_select)\n",
    "    with open(os.path.join(case_folder, 'info.txt'), 'w') as wp:\n",
    "        wp.write('Processing {} sequences\\n'.format(df_info[0]))\n",
    "        wp.write('Processing {} pairs'.format(df_info[1]))\n",
    "    \n",
    "    \n",
    "\n",
    "    outputfilename = '{}_{}.csv'.format\n",
    "    ALLCOLUMN = ['pre2', 'pre', 'error', 'post', 'post2']\n",
    "    column_select_dict = {\n",
    "        'error':[ALLCOLUMN[2]],\n",
    "        'preError':ALLCOLUMN[1:3],\n",
    "        'errorPost':ALLCOLUMN[2:4],\n",
    "        'pre2Error':ALLCOLUMN[:3],\n",
    "        'preErrorPost':ALLCOLUMN[1:4],\n",
    "        'errorPost2':ALLCOLUMN[2:],\n",
    "        'pre2ErrorPost':ALLCOLUMN[:4],\n",
    "        'preErrorPost2':ALLCOLUMN[1:],\n",
    "        'pre2ErrorPost2':ALLCOLUMN\n",
    "    }\n",
    "\n",
    "    for key, select_columns in column_select_dict.items():\n",
    "        newdf = outputprepost(df, select_columns+['corr'])\n",
    "        newdf.to_csv(\n",
    "            os.path.join(case_folder, outputfilename(case_token, key)),\n",
    "            sep='\\t')\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File output to ./extractUDN_new/remove_numeng\n",
      "= Processing 135927 sequences\n",
      "= Processing 86858 pairs\n",
      "Done.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    input_filename = './extractUDN_new/all_seqraw.txt'\n",
    "    groundTruth_filename = './extractUDN_new/all_gtraw.txt'\n",
    "\n",
    "    # ptn = re.compile('[0-9A-Za-z：\\–－\\-•%％&（\\(\\）)\\.\\*\\,、\\/／\\:\\?_~∼˙‘’“”《「〞※」+＋＞→■○●─°・★〇℃éＯ．=＝…\\s]')\n",
    "    kick_ptn = '[0-9]'\n",
    "    special_select = False\n",
    "    case_token = 'num'\n",
    "    main(input_filename, groundTruth_filename, kick_ptn, special_select, case_token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
