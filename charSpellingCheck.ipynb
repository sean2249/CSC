{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from model.case import CASE\n",
    "from model.lm import LM\n",
    "from model.ncm import NCM\n",
    "\n",
    "import os \n",
    "import pickle\n",
    "import math\n",
    "from collections import namedtuple, defaultdict\n",
    "import re\n",
    "import pandas as pd \n",
    "\n",
    "import time \n",
    "import sys, getopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_root = '/home/kiwi/udn_data/training_confusion/'\n",
    "# data_root = 'G:/UDN/training_confusion/'\n",
    "channel_filename = data_root+'channelModel.pkl'\n",
    "lm_filename = data_root+'sinica.corpus.seg.char.lm'\n",
    "# lm_filename = data_root+'trigram_2.lm'\n",
    "# lm_filename = '/home/kiwi/Documents/udn_data/trigram.lm'\n",
    "ncmEx_filename = data_root+'dict_word.txt'\n",
    "con_filename = './extractUDN_prepost/all.csv'\n",
    "\n",
    "# candsExpand = CANDSEXPAND(ncmEx_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CASE:\n",
    "    def __init__(self, sentence, addS=0):\n",
    "        self.query=[]\n",
    "        if addS==1:\n",
    "            if len(sentence)>0:\n",
    "                self.query.append('<s>')\n",
    "                self.query.extend(list(sentence))\n",
    "                self.query.append('</s>')\n",
    "        else:\n",
    "            self.query=list(sentence)\n",
    "        self.length = len(self.query)\n",
    "    def candsGet(self, ncm, candsExpandTag=0):\n",
    "        ncm_stats = namedtuple('ncm_prob', 'ch,prob')\n",
    "        self.cands = []\n",
    "        for idx,cur_ch in enumerate(self.query):\n",
    "            cur_cands = ncm.cand(cur_ch)\n",
    "            tmp =[]          \n",
    "            # Have more than one candidatae (Except me)\n",
    "            if len(cur_cands)>=1:\n",
    "                for cand in cur_cands:\n",
    "                    # Put original char to first\n",
    "                    if cand[0]==cur_ch:                        \n",
    "                        tmp.insert(0,ncm_stats(cand[0],cand[1]))\n",
    "                    else:\n",
    "                        tmp.append(ncm_stats(cand[0],cand[1]))\n",
    "            else:\n",
    "                tmp.append(ncm_stats(cur_ch,1))        \n",
    "            # ========  \n",
    "            # Others\n",
    "            # ========  \n",
    "            if candsExpandTag != 0:\n",
    "                prob_sample = 0.0000000005            \n",
    "                if idx==0: \n",
    "                    pre_char='' \n",
    "                else: \n",
    "                    pre_char = self.query[idx-1]\n",
    "                if idx==self.length-1:                \n",
    "                    post_char='' \n",
    "                else: \n",
    "                    post_char=self.query[idx+1]            \n",
    "                for cand in cande.cand(pre_char,post_char,1):\n",
    "                    tmp.append(ncm_stats(cand, prob_sample)) \n",
    "            # ========  \n",
    "            # Others\n",
    "            # ========  \n",
    "            \n",
    "            self.cands.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CONFUSION:\n",
    "    def __init__(self, filename, con_log_file):\n",
    "        print('Loading Preprocess_RuleBased model {} ...'.format(filename))\n",
    "        self.df = pd.DataFrame.from_csv(con_filename)\n",
    "        if os.path.exists(con_log_file):\n",
    "            os.remove(con_log_file)\n",
    "    \n",
    "    def organize(self, label=[], threshold=10):\n",
    "        if set(label).issubset(set(self.df)) and len(label)>0:\n",
    "            self.ptable = self.df.groupby(label)\n",
    "        else:\n",
    "            label = ['pre','error','post','corr']\n",
    "            self.ptable = self.df.groupby(label)\n",
    "            \n",
    "        self.ptable = self.speDataframe(self.ptable)\n",
    "        self.ptable = self.ptable.loc[self.ptable['count']>threshold]\n",
    "        self.label_len = len(label)-1\n",
    "        \n",
    "    def speDataframe(self,_gg):\n",
    "        _ggS = _gg.size()\n",
    "        _ggDF = pd.DataFrame(_ggS,columns=['count'])\n",
    "        _ggDF_sort = _ggDF.sort_values('count', ascending=False)\n",
    "\n",
    "        return _ggDF_sort\n",
    "    \n",
    "    def scan(self, orig_seq='這邊的空氣污染很嚴重的市佔率'):\n",
    "        # Consider the length of new lable\n",
    "        \n",
    "        seqs = [orig_seq[idx-(self.label_len-1):idx+1] for idx in range(self.label_len-1, len(orig_seq))] \\\n",
    "        if len(orig_seq) >= self.label_len else []\n",
    "        \n",
    "        self._check = dict((''.join(element[:-1]), element[-1]) for element in self.ptable.index.tolist())\n",
    "\n",
    "        new = list(orig_seq)\n",
    "        output = []\n",
    "        for idx,s in enumerate(seqs, 1):\n",
    "            flag = self._check.get(s)\n",
    "            if flag:\n",
    "                output.append((idx,flag))\n",
    "                new[idx] = flag\n",
    "        new = ''.join(new)\n",
    "\n",
    "        return (new, output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def viterbi_ng(seq, par, show=0):\n",
    "    # LM,NCM required\n",
    "    para = par.get('lmNcm_weight', None)\n",
    "    ng_num = par.get('ngnum', None)\n",
    "    \n",
    "    case = CASE(seq, 1)\n",
    "    case.candsGet(ncm)    \n",
    "    \n",
    "    sect_named = namedtuple('sect_stat', 'score, length, idx, seq')\n",
    "    \n",
    "    cands4all =[]\n",
    "    pre_cand_lst = []\n",
    "    \n",
    "    for cur_idx, cur_ch in enumerate(case.query):  \n",
    "        section = []\n",
    "        if show==1:\n",
    "            print('==========')\n",
    "            print(cur_idx, cur_ch, ' '.join([x.ch for x in case.cands[cur_idx]]))\n",
    "        \n",
    "\n",
    "        if cur_idx==0 and cur_ch=='<s>':\n",
    "            section.append({'from_to':'<s>', 'score':0.0, 'seq':['<s>'], 'idx_seq':[0]})\n",
    "\n",
    "        elif cur_idx>0:                \n",
    "            for cand_idx, cand in enumerate(case.cands[cur_idx]):\n",
    "                # Add global \n",
    "                sect_ncm = math.log10(cand.prob)              \n",
    "            \n",
    "                batch = []\n",
    "                \n",
    "                # lm.scoring(list)\n",
    "                for pre_idx, pre_cand in enumerate(pre_cand_lst):\n",
    "                    batch_seq = pre_cand['seq'] + [cand.ch]\n",
    "                    \n",
    "                    # Compute before?\n",
    "                    batch_lm = lm.scoring(batch_seq[-ng_num:], ng_num) + pre_cand['score']\n",
    "                    batch_score = (para[0]*batch_lm+para[1]*sect_ncm)\n",
    "                    \n",
    "                    if show==1: \n",
    "                        print('Seq:%s\\tpre:%.2f\\tbLM:%.2f\\tNCM:%.2f\\tTotal:%.2f' \\\n",
    "                              %(batch_seq[-ng_num:], pre_cand['score'], batch_lm, sect_ncm, batch_score))\n",
    "                    \n",
    "                    ttt = list(pre_cand['idx_seq'])                    \n",
    "                    ttt.append(cand_idx)\n",
    "                \n",
    "                    batch_dict = {'from_to':batch_seq[-ng_num:], 'score':batch_score, \\\n",
    "                                  'seq':batch_seq, 'idx_seq':ttt}\n",
    "                    \n",
    "                    batch.append(batch_dict)               \n",
    "                \n",
    "                best = max(batch, key=lambda x:x['score'])\n",
    "                if show==1: \n",
    "                    print('== Choose Seq:%s\\t NCM:%.2f\\tTotal:%.2f'\\\n",
    "                         %(best['from_to'], sect_ncm, best['score']))\n",
    "                                \n",
    "                section.append(best)\n",
    "                \n",
    "        pre_cand_lst = list(section)\n",
    "        cands4all.append(pre_cand_lst)\n",
    "    \n",
    "    winner = max(pre_cand_lst, key=lambda x:x['score'])\n",
    "    output = ''.join(winner['seq'][1:-1])\n",
    "        \n",
    "    result = dict(orig=seq, correct=output, log=cands4all, win=winner, cor_idx=winner['idx_seq'][1:-1])    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def viterbi_ng_fix(seq, par, show=0):\n",
    "    # LM,NCM required\n",
    "    para = par.get('lmNcm_weight', None)\n",
    "    ng_num = par.get('ngnum', None)\n",
    "    \n",
    "    \n",
    "    ignore_idx = par.get('ignore_idx', None)\n",
    "    \n",
    "    case = CASE(seq, 1)\n",
    "    case.candsGet(ncm)    \n",
    "    \n",
    "    sect_named = namedtuple('sect_stat', 'score, length, idx, seq')\n",
    "    \n",
    "    cands4all =[]\n",
    "    pre_cand_lst = []\n",
    "    \n",
    "    for cur_idx, cur_ch in enumerate(case.query):  \n",
    "        section = []\n",
    "        if show==1:\n",
    "            print('==========')\n",
    "            print(cur_idx, cur_ch, ' '.join([x.ch for x in case.cands[cur_idx]]))\n",
    "        \n",
    "\n",
    "        if cur_idx==0 and cur_ch=='<s>':\n",
    "            section.append({'from_to':'<s>', 'score':0.0, 'seq':['<s>'], 'idx_seq':[0]})\n",
    "\n",
    "        elif cur_idx>0:                \n",
    "            for cand_idx, cand in enumerate(case.cands[cur_idx]):\n",
    "                # Add global \n",
    "                sect_ncm = math.log10(cand.prob)              \n",
    "            \n",
    "                batch = []\n",
    "                \n",
    "                # lm.scoring(list)\n",
    "                for pre_idx, pre_cand in enumerate(pre_cand_lst):\n",
    "                    batch_seq = pre_cand['seq'] + [cand.ch]\n",
    "                    \n",
    "                    # Compute before?\n",
    "                    batch_lm = lm.scoring(batch_seq[-ng_num:], ng_num) + pre_cand['score']\n",
    "                    batch_score = (para[0]*batch_lm+para[1]*sect_ncm)\n",
    "                    \n",
    "                    if show==1: \n",
    "                        print('Seq:%s\\tpre:%.2f\\tbLM:%.2f\\tNCM:%.2f\\tTotal:%.2f' \\\n",
    "                              %(batch_seq[-ng_num:], pre_cand['score'], batch_lm, sect_ncm, batch_score))\n",
    "                    \n",
    "                    ttt = list(pre_cand['idx_seq'])                    \n",
    "                    ttt.append(cand_idx)\n",
    "                \n",
    "                    batch_dict = {'from_to':batch_seq[-ng_num:], 'score':batch_score, \\\n",
    "                                  'seq':batch_seq, 'idx_seq':ttt}\n",
    "                    \n",
    "                    batch.append(batch_dict)               \n",
    "                \n",
    "                best = max(batch, key=lambda x:x['score'])\n",
    "                if show==1: \n",
    "                    print('== Choose Seq:%s\\t NCM:%.2f\\tTotal:%.2f'\\\n",
    "                         %(best['from_to'], sect_ncm, best['score']))\n",
    "                                \n",
    "                section.append(best)\n",
    "                \n",
    "        pre_cand_lst = list(section)\n",
    "        cands4all.append(pre_cand_lst)\n",
    "    \n",
    "    winner = max(pre_cand_lst, key=lambda x:x['score'])\n",
    "    output = ''.join(winner['seq'][1:-1])\n",
    "        \n",
    "    result = dict(orig=seq, correct=output, log=cands4all, win=winner, cor_idx=winner['idx_seq'][1:-1])    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_test(testfilename, resultname, par):    \n",
    "    show = par.get('show',0)\n",
    "    \n",
    "    with open(testfilename, 'r',encoding='utf8') as fp, open(resultname,'w',encoding='utf8') as wp:\n",
    "        for line in fp:        \n",
    "            line = line.strip('\\n')\n",
    "            idx1 = line.find('=')+1\n",
    "            idx2 = line.find(')')\n",
    "            dataNum = line[idx1:idx2]\n",
    "            seq = line[idx2+2:]        \n",
    "\n",
    "            if show==1: print('=====')\n",
    "            print(dataNum)   \n",
    "            \n",
    "            errors = batch(seq, par)\n",
    "            \n",
    "            wp.write(dataNum)\n",
    "            if len(errors)!=0:\n",
    "                for error in errors:\n",
    "                    wp.write(', ')\n",
    "                    wp.write(', '.join(error))\n",
    "            else:\n",
    "                wp.write(', 0')\n",
    "                \n",
    "            wp.write('\\n')\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def main(argv, par):\n",
    "    if len(argv) < 3:\n",
    "        print('Usage: python filename.py token test_file1 test_file2')\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        data_length = len(argv)-2\n",
    "        test_data = []\n",
    "\n",
    "        token = argv[1]\n",
    "\n",
    "        for idx, item in enumerate(argv[2:],1):\n",
    "            test_data_batch = item\n",
    "            print('%d/%d- loading %s...'\\\n",
    "                    %(idx, data_length, test_data_batch))\n",
    "            if not(os.path.exists(test_data_batch)):\n",
    "                print('Unable to load file')\n",
    "            else:\n",
    "                test_data.append(test_data_batch)\n",
    "              \n",
    "    for idx, batch_name in enumerate(test_data, 1):\n",
    "        print('=========')\n",
    "        print('Batch %d-%s' %(idx, batch_name))\n",
    "        print('=========')\n",
    "        result_name = './test_15/re_%s_%d.txt' %(str(token), idx)\n",
    "        run_test(batch_name, result_name, par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def debug_ncm(ch, append=None, value= 0.05, show=0):    \n",
    "    tt = ncm.cand(ch)\n",
    "    if show==1:\n",
    "        for d in tt:\n",
    "            print(d)\n",
    "        \n",
    "    if append:\n",
    "        ncm.table[ch][append] = value\n",
    "        if show==1:\n",
    "            print('== Add %s to Set of %s' %(append,ch))\n",
    "    else:\n",
    "        return tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def debug_lm(seq, ngnum=2):\n",
    "    lst = seq.split()\n",
    "    for item in lst:\n",
    "        print(item, lm.scoring(item, ngnum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seperateSeq(seq):\n",
    "    pattern = re.compile('[，。！]')\n",
    "    \n",
    "    pre_idx=0\n",
    "    output = []\n",
    "    for idx, ch in enumerate(seq):\n",
    "        if pattern.search(ch):\n",
    "            tmp = seq[pre_idx:idx+1]\n",
    "            output.append(tmp)\n",
    "            pre_idx = idx+1\n",
    "    \n",
    "    if pre_idx<len(seq):\n",
    "        tmp = seq[pre_idx:idx+1]\n",
    "        output.append(tmp)\n",
    "        \n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nnn(seq, show):\n",
    "    \n",
    "    case = CASE(seq, 1)  \n",
    "    case.candsGet(ncm)    \n",
    "\n",
    "    for cur_idx, cur_ch in enumerate(case.query):\n",
    "        \n",
    "        if show==1:\n",
    "            print('==========')\n",
    "            print(cur_idx, cur_ch, ' '.join([x.ch for x in case.cands[cur_idx]]))\n",
    "            \n",
    "        \n",
    "    \n",
    "    '''\n",
    "    Past \n",
    "    '''\n",
    "        \n",
    "    sect_named = namedtuple('sect_stat', 'score, length, idx, seq')\n",
    "    \n",
    "    cands4all =[]\n",
    "    pre_cand_lst = []\n",
    "    \n",
    "    for cur_idx, cur_ch in enumerate(case.query):  \n",
    "        section = []\n",
    "        if show==1:\n",
    "            print('==========')\n",
    "            print(cur_idx, cur_ch, ' '.join([x.ch for x in case.cands[cur_idx]]))\n",
    "        \n",
    "\n",
    "        if cur_idx==0 and cur_ch=='<s>':\n",
    "            section.append({'from_to':'<s>', 'score':0.0, 'seq':['<s>'], 'idx_seq':[0]})\n",
    "\n",
    "        elif cur_idx>0:                \n",
    "            for cand_idx, cand in enumerate(case.cands[cur_idx]):\n",
    "                sect_ncm = math.log10(cand.prob)              \n",
    "            \n",
    "                batch = []\n",
    "                \n",
    "                # lm.scoring(list)\n",
    "                for pre_idx, pre_cand in enumerate(pre_cand_lst):\n",
    "                    batch_seq = pre_cand['seq'] + [cand.ch]\n",
    "                    \n",
    "                    # Compute before?\n",
    "                    batch_lm = lm.scoring(batch_seq[-ng_num:], ng_num) + pre_cand['score']\n",
    "                    batch_score = (para[0]*batch_lm+para[1]*sect_ncm)\n",
    "                    \n",
    "                    if show==1: \n",
    "                        print('Seq:%s\\tpre:%.2f\\tbLM:%.2f\\tNCM:%.2f\\tTotal:%.2f' \\\n",
    "                              %(batch_seq[-ng_num:], pre_cand['score'], batch_lm, sect_ncm, batch_score))\n",
    "                    \n",
    "                    ttt = list(pre_cand['idx_seq'])                    \n",
    "                    ttt.append(cand_idx)\n",
    "                \n",
    "                    batch_dict = {'from_to':batch_seq[-ng_num:], 'score':batch_score, \\\n",
    "                                  'seq':batch_seq, 'idx_seq':ttt}\n",
    "                    \n",
    "                    batch.append(batch_dict)               \n",
    "                \n",
    "                best = max(batch, key=lambda x:x['score'])\n",
    "                if show==1: \n",
    "                    print('== Choose Seq:%s\\t NCM:%.2f\\tTotal:%.2f'\\\n",
    "                         %(best['from_to'], sect_ncm, best['score']))\n",
    "                                \n",
    "                section.append(best)\n",
    "                \n",
    "        pre_cand_lst = list(section)\n",
    "        cands4all.append(pre_cand_lst)\n",
    "    \n",
    "    winner = max(pre_cand_lst, key=lambda x:x['score'])\n",
    "    output = ''.join(winner['seq'][1:-1])\n",
    "        \n",
    "    result = dict(orig=seq, correct=output, log=cands4all, win=winner, cor_idx=winner['idx_seq'][1:-1])    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch(seq, par = {\n",
    "        'lmNcm_weight':[0.7,0.3],\n",
    "        'ngnum':3,\n",
    "        'pre_con':True,\n",
    "        'con_log_file':'special_case4con.txt',\n",
    "        'show':0        \n",
    "    }, show=0):            \n",
    "    \n",
    "    con_log_file = par.get('con_log_file', 'special_case4con.txt')\n",
    "    \n",
    "    sub_seqs = seperateSeq(seq)\n",
    "    \n",
    "    total_length = 0\n",
    "    error_dict = dict()\n",
    "    for sub in sub_seqs:\n",
    "        if show==1: \n",
    "            print('pre:', sub, len(sub))\n",
    "        '''\n",
    "        Preprocess\n",
    "        '''\n",
    "        if par.get('pre_con',False):\n",
    "            (sub, output) = con_preprocess.scan(sub)\n",
    "            if len(output)>0: \n",
    "                with open(con_log_file,'a',encoding='utf8') as wp:\n",
    "                    wp.write(sub)\n",
    "                    for (idx,ch) in output:\n",
    "                        wp.write('{}\\t{}\\t'.format(str(idx),ch))\n",
    "                    wp.write('\\n')\n",
    "            con_dict = dict((str(idx+total_length+1), ch) for idx,ch in output)\n",
    "            error_dict.update(con_dict)\n",
    "        \n",
    "        '''\n",
    "        Viterbi\n",
    "        '''\n",
    "        if show==1: print(sub)\n",
    "        result = viterbi_ng(sub, par, show)\n",
    "        tmp_pos   = [i for i,e in enumerate(result['cor_idx']) if e!=0]\n",
    "        pos_error = [str(idx+total_length+1) for idx in tmp_pos]     \n",
    "        ch_error  = [result['correct'][int(idx)] for idx in tmp_pos]\n",
    "        \n",
    "        if show==1:\n",
    "            for idx in tmp_pos:\n",
    "                print(result['correct'][int(idx)])\n",
    "            print(result['orig'])\n",
    "            print(result['correct'])  \n",
    "        \n",
    "        viter_dict = dict((p,s) for p,s in zip(pos_error, ch_error))\n",
    "        error_dict.update(viter_dict)\n",
    "        \n",
    "        '''\n",
    "        End\n",
    "        '''\n",
    "        total_length += len(sub)\n",
    "        \n",
    "    return sorted(error_dict.items(), key=lambda x:int(x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "debug_lm('市占率 視障率')\n",
    "\n",
    "lm.scoring('市占率',show=1)\n",
    "\n",
    "lm.scoring('視障率',show=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class NCM:\n",
    "#     def __init__(self, channel_filename):\n",
    "#         print('Loading channel model %s ...' %(channel_filename))\n",
    "#         with open(channel_filename, 'rb') as fp:\n",
    "#             self.table = pickle.load(fp, encoding='utf8')\n",
    "#         #  self.table = pickle.load(open(channel_filename,'rb'), encoding='utf8')\n",
    "#     def cand(self, cur_char, show=0):\n",
    "#         query_cands = []\n",
    "#         if cur_char in self.table:\n",
    "#             query_cands = self.table[cur_char].items()            \n",
    "            \n",
    "#         if show==1:\n",
    "#             for cands in query_cands:\n",
    "#                 print(cands)\n",
    "#         return query_cands\n",
    "#     def special_zero(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading language model /home/kiwi/udn_data/training_confusion/sinica.corpus.seg.char.lm ...\n",
      "Loading channel model /home/kiwi/udn_data/training_confusion/channelModel.pkl ...\n",
      "Loading Preprocess_RuleBased model ./extractUDN_prepost/all.csv ...\n"
     ]
    }
   ],
   "source": [
    "lm = LM(lm_filename)\n",
    "ncm = NCM(channel_filename)\n",
    "con_preprocess = CONFUSION(con_filename, con_log_file='special_case4con.txt')\n",
    "con_preprocess.organize(label=['pre','error','corr'], threshold=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def t1(sys, par):\n",
    "    if len(sys.argv) < 3:\n",
    "        print('Usage: python filename.py token test_file1')\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        token     = sys.argv[1]\n",
    "        test_data = sys.argv[2]\n",
    "        \n",
    "        ncm_insert_vals = [0.005,0.01,0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85]\n",
    "\n",
    "        for ncm_insert_val in ncm_insert_vals:\n",
    "            result_name = './test_15/re_{}_{}.txt'.format\n",
    "            ncm_tag = str(ncm_insert_val)[2:]\n",
    "            \n",
    "#             del ncm\n",
    "            channel_filename = './confusionAdd/confusionSet_{}.pkl'.format(ncm_tag)\n",
    "            ncm = NCM(channel_filename)\n",
    "\n",
    "            run_test(test_data, result_name(token, ncm_tag), par)\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def t2(sys, par):\n",
    "    global ncm\n",
    "    if len(sys.argv) < 3:\n",
    "        print('Usage: python filename.py token channel_model test_data')\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        token     = sys.argv[1]\n",
    "        channel_model = sys.argv[2]\n",
    "        test_data = sys.argv[3]\n",
    "        \n",
    "        del ncm\n",
    "        \n",
    "        ncm = NCM(channel_model)\n",
    "        \n",
    "        result_name = './test_15/re_{}.txt'.format\n",
    "               \n",
    "        run_test(test_data, result_name(token), par)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def t3(sys, par):\n",
    "    global lm\n",
    "    if len(sys.argv) < 4:\n",
    "        print('Usage: python filename.py token language_model test_data ngram')\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        token     = sys.argv[1]\n",
    "        language_model = sys.argv[2]\n",
    "        test_data = sys.argv[3]\n",
    "        par['ngnum'] = int(sys.argv[4])\n",
    "        \n",
    "        del lm \n",
    "        \n",
    "        lm = LM(language_model)\n",
    "        \n",
    "        result_name = './test_15/re_{}.txt'.format\n",
    "        run_test(test_data, result_name(token), par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    par = {\n",
    "        'lmNcm_weight':[0.7,0.3],\n",
    "        'ngnum':3,\n",
    "        'pre_con':False,\n",
    "        'con_log_file':'special_case4con.txt',\n",
    "        'show':1\n",
    "    }\n",
    "    \n",
    "#     t3(sys, par)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre: 我吃的範 4\n",
      "我吃的範\n",
      "==========\n",
      "0 <s> <s>\n",
      "==========\n",
      "1 我 我 牟 俄\n",
      "Seq:['<s>', '我']\tpre:0.00\tbLM:-1.41\tNCM:-0.00\tTotal:-0.99\n",
      "== Choose Seq:['<s>', '我']\t NCM:-0.00\tTotal:-0.99\n",
      "Seq:['<s>', '牟']\tpre:0.00\tbLM:-5.59\tNCM:-4.03\tTotal:-5.12\n",
      "== Choose Seq:['<s>', '牟']\t NCM:-4.03\tTotal:-5.12\n",
      "Seq:['<s>', '俄']\tpre:0.00\tbLM:-4.53\tNCM:-4.64\tTotal:-4.56\n",
      "== Choose Seq:['<s>', '俄']\t NCM:-4.64\tTotal:-4.56\n",
      "==========\n",
      "2 吃 吃 吟\n",
      "Seq:['<s>', '我', '吃']\tpre:-0.99\tbLM:-5.65\tNCM:-0.00\tTotal:-3.96\n",
      "Seq:['<s>', '牟', '吃']\tpre:-5.12\tbLM:-14.51\tNCM:-0.00\tTotal:-10.16\n",
      "Seq:['<s>', '俄', '吃']\tpre:-4.56\tbLM:-12.93\tNCM:-0.00\tTotal:-9.05\n",
      "== Choose Seq:['<s>', '我', '吃']\t NCM:-0.00\tTotal:-3.96\n",
      "Seq:['<s>', '我', '吟']\tpre:-0.99\tbLM:-8.27\tNCM:-4.73\tTotal:-7.21\n",
      "Seq:['<s>', '牟', '吟']\tpre:-5.12\tbLM:-15.40\tNCM:-4.73\tTotal:-12.20\n",
      "Seq:['<s>', '俄', '吟']\tpre:-4.56\tbLM:-13.82\tNCM:-4.73\tTotal:-11.09\n",
      "== Choose Seq:['<s>', '我', '吟']\t NCM:-4.73\tTotal:-7.21\n",
      "==========\n",
      "3 的 的 豹 皂\n",
      "Seq:['我', '吃', '的']\tpre:-3.96\tbLM:-10.52\tNCM:-0.00\tTotal:-7.37\n",
      "Seq:['我', '吟', '的']\tpre:-7.21\tbLM:-21.69\tNCM:-0.00\tTotal:-15.18\n",
      "== Choose Seq:['我', '吃', '的']\t NCM:-0.00\tTotal:-7.37\n",
      "Seq:['我', '吃', '豹']\tpre:-3.96\tbLM:-14.62\tNCM:-3.79\tTotal:-11.37\n",
      "Seq:['我', '吟', '豹']\tpre:-7.21\tbLM:-24.76\tNCM:-3.79\tTotal:-18.47\n",
      "== Choose Seq:['我', '吃', '豹']\t NCM:-3.79\tTotal:-11.37\n",
      "Seq:['我', '吃', '皂']\tpre:-3.96\tbLM:-15.18\tNCM:-1.55\tTotal:-11.09\n",
      "Seq:['我', '吟', '皂']\tpre:-7.21\tbLM:-25.32\tNCM:-1.55\tTotal:-18.19\n",
      "== Choose Seq:['我', '吃', '皂']\t NCM:-1.55\tTotal:-11.09\n",
      "==========\n",
      "4 範 範 泛 汎 梵 放 犯 販 飯 氾 范\n",
      "Seq:['吃', '的', '範']\tpre:-7.37\tbLM:-15.26\tNCM:-0.82\tTotal:-10.93\n",
      "Seq:['吃', '豹', '範']\tpre:-11.37\tbLM:-28.51\tNCM:-0.82\tTotal:-20.20\n",
      "Seq:['吃', '皂', '範']\tpre:-11.09\tbLM:-29.26\tNCM:-0.82\tTotal:-20.73\n",
      "== Choose Seq:['吃', '的', '範']\t NCM:-0.82\tTotal:-10.93\n",
      "Seq:['吃', '的', '泛']\tpre:-7.37\tbLM:-16.46\tNCM:-2.71\tTotal:-12.33\n",
      "Seq:['吃', '豹', '泛']\tpre:-11.37\tbLM:-28.92\tNCM:-2.71\tTotal:-21.06\n",
      "Seq:['吃', '皂', '泛']\tpre:-11.09\tbLM:-29.67\tNCM:-2.71\tTotal:-21.58\n",
      "== Choose Seq:['吃', '的', '泛']\t NCM:-2.71\tTotal:-12.33\n",
      "Seq:['吃', '的', '汎']\tpre:-7.37\tbLM:-17.75\tNCM:-2.23\tTotal:-13.09\n",
      "Seq:['吃', '豹', '汎']\tpre:-11.37\tbLM:-29.84\tNCM:-2.23\tTotal:-21.55\n",
      "Seq:['吃', '皂', '汎']\tpre:-11.09\tbLM:-30.59\tNCM:-2.23\tTotal:-22.08\n",
      "== Choose Seq:['吃', '的', '汎']\t NCM:-2.23\tTotal:-13.09\n",
      "Seq:['吃', '的', '梵']\tpre:-7.37\tbLM:-16.94\tNCM:-3.90\tTotal:-13.03\n",
      "Seq:['吃', '豹', '梵']\tpre:-11.37\tbLM:-29.49\tNCM:-3.90\tTotal:-21.81\n",
      "Seq:['吃', '皂', '梵']\tpre:-11.09\tbLM:-30.25\tNCM:-3.90\tTotal:-22.34\n",
      "== Choose Seq:['吃', '的', '梵']\t NCM:-3.90\tTotal:-13.03\n",
      "Seq:['吃', '的', '放']\tpre:-7.37\tbLM:-15.55\tNCM:-7.04\tTotal:-13.00\n",
      "Seq:['吃', '豹', '放']\tpre:-11.37\tbLM:-28.04\tNCM:-7.04\tTotal:-21.74\n",
      "Seq:['吃', '皂', '放']\tpre:-11.09\tbLM:-28.80\tNCM:-7.04\tTotal:-22.27\n",
      "== Choose Seq:['吃', '的', '放']\t NCM:-7.04\tTotal:-13.00\n",
      "Seq:['吃', '的', '犯']\tpre:-7.37\tbLM:-16.03\tNCM:-5.24\tTotal:-12.79\n",
      "Seq:['吃', '豹', '犯']\tpre:-11.37\tbLM:-28.55\tNCM:-5.24\tTotal:-21.56\n",
      "Seq:['吃', '皂', '犯']\tpre:-11.09\tbLM:-29.31\tNCM:-5.24\tTotal:-22.09\n",
      "== Choose Seq:['吃', '的', '犯']\t NCM:-5.24\tTotal:-12.79\n",
      "Seq:['吃', '的', '販']\tpre:-7.37\tbLM:-16.40\tNCM:-3.44\tTotal:-12.51\n",
      "Seq:['吃', '豹', '販']\tpre:-11.37\tbLM:-28.77\tNCM:-3.44\tTotal:-21.17\n",
      "Seq:['吃', '皂', '販']\tpre:-11.09\tbLM:-29.53\tNCM:-3.44\tTotal:-21.70\n",
      "== Choose Seq:['吃', '的', '販']\t NCM:-3.44\tTotal:-12.51\n",
      "Seq:['吃', '的', '飯']\tpre:-7.37\tbLM:-15.73\tNCM:-5.05\tTotal:-12.52\n",
      "Seq:['吃', '豹', '飯']\tpre:-11.37\tbLM:-28.57\tNCM:-5.05\tTotal:-21.51\n",
      "Seq:['吃', '皂', '飯']\tpre:-11.09\tbLM:-29.33\tNCM:-5.05\tTotal:-22.04\n",
      "== Choose Seq:['吃', '的', '飯']\t NCM:-5.05\tTotal:-12.52\n",
      "Seq:['吃', '的', '氾']\tpre:-7.37\tbLM:-16.79\tNCM:-2.93\tTotal:-12.63\n",
      "Seq:['吃', '豹', '氾']\tpre:-11.37\tbLM:-29.23\tNCM:-2.93\tTotal:-21.34\n",
      "Seq:['吃', '皂', '氾']\tpre:-11.09\tbLM:-29.98\tNCM:-2.93\tTotal:-21.87\n",
      "== Choose Seq:['吃', '的', '氾']\t NCM:-2.93\tTotal:-12.63\n",
      "Seq:['吃', '的', '范']\tpre:-7.37\tbLM:-16.36\tNCM:-5.22\tTotal:-13.02\n",
      "Seq:['吃', '豹', '范']\tpre:-11.37\tbLM:-28.95\tNCM:-5.22\tTotal:-21.83\n",
      "Seq:['吃', '皂', '范']\tpre:-11.09\tbLM:-29.71\tNCM:-5.22\tTotal:-22.36\n",
      "== Choose Seq:['吃', '的', '范']\t NCM:-5.22\tTotal:-13.02\n",
      "==========\n",
      "5 </s> </s>\n",
      "Seq:['的', '範', '</s>']\tpre:-10.93\tbLM:-22.63\tNCM:0.00\tTotal:-15.84\n",
      "Seq:['的', '泛', '</s>']\tpre:-12.33\tbLM:-24.02\tNCM:0.00\tTotal:-16.81\n",
      "Seq:['的', '汎', '</s>']\tpre:-13.09\tbLM:-25.72\tNCM:0.00\tTotal:-18.00\n",
      "Seq:['的', '梵', '</s>']\tpre:-13.03\tbLM:-24.98\tNCM:0.00\tTotal:-17.48\n",
      "Seq:['的', '放', '</s>']\tpre:-13.00\tbLM:-24.26\tNCM:0.00\tTotal:-16.98\n",
      "Seq:['的', '犯', '</s>']\tpre:-12.79\tbLM:-24.75\tNCM:0.00\tTotal:-17.33\n",
      "Seq:['的', '販', '</s>']\tpre:-12.51\tbLM:-24.23\tNCM:0.00\tTotal:-16.96\n",
      "Seq:['的', '飯', '</s>']\tpre:-12.52\tbLM:-23.80\tNCM:0.00\tTotal:-16.66\n",
      "Seq:['的', '氾', '</s>']\tpre:-12.63\tbLM:-26.08\tNCM:0.00\tTotal:-18.26\n",
      "Seq:['的', '范', '</s>']\tpre:-13.02\tbLM:-24.54\tNCM:0.00\tTotal:-17.18\n",
      "== Choose Seq:['的', '範', '</s>']\t NCM:0.00\tTotal:-15.84\n",
      "我吃的範\n",
      "我吃的範\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch('我吃的範', show=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "範 -3.510874\n",
      "飯 -3.574116\n"
     ]
    }
   ],
   "source": [
    "debug_lm('範 飯')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
