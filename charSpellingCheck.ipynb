{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from model.case import CASE\n",
    "from model.model import LM, CASE, NCM\n",
    "\n",
    "\n",
    "import os \n",
    "import pickle\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd \n",
    "\n",
    "import time \n",
    "import sys, getopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_root = '/home/kiwi/udn_data/training_confusion/'\n",
    "data_root = 'G:/UDN/training_confusion/'\n",
    "channel_filename = data_root+'channelModel.pkl'\n",
    "lm_filename = data_root+'sinica.corpus.seg.char.lm'\n",
    "# lm_filename = data_root+'trigram_2.lm'\n",
    "# lm_filename = '/home/kiwi/Documents/udn_data/trigram.lm'\n",
    "ncmEx_filename = data_root+'dict_word.txt'\n",
    "con_filename = './extractUDN_prepost/all.csv'\n",
    "\n",
    "# candsExpand = CANDSEXPAND(ncmEx_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CONFUSION:\n",
    "    def __init__(self, filename, con_log_file):\n",
    "        print('Loading Preprocess_RuleBased model {} ...'.format(filename))\n",
    "        self.df = pd.DataFrame.from_csv(con_filename)\n",
    "        if os.path.exists(con_log_file):\n",
    "            os.remove(con_log_file)\n",
    "    \n",
    "    def organize(self, label=[], threshold=10):\n",
    "        if set(label).issubset(set(self.df)) and len(label)>0:\n",
    "            self.ptable = self.df.groupby(label)\n",
    "        else:\n",
    "            label = ['pre','error','post','corr']\n",
    "            self.ptable = self.df.groupby(label)\n",
    "            \n",
    "        self.ptable = self.speDataframe(self.ptable)\n",
    "        self.ptable = self.ptable.loc[self.ptable['count']>threshold]\n",
    "        self.label_len = len(label)-1\n",
    "        \n",
    "    def speDataframe(self,_gg):\n",
    "        _ggS = _gg.size()\n",
    "        _ggDF = pd.DataFrame(_ggS,columns=['count'])\n",
    "        _ggDF_sort = _ggDF.sort_values('count', ascending=False)\n",
    "\n",
    "        return _ggDF_sort\n",
    "    \n",
    "    def scan(self, orig_seq='這邊的空氣污染很嚴重的市佔率'):\n",
    "        # Consider the length of new lable\n",
    "        \n",
    "        seqs = [orig_seq[idx-(self.label_len-1):idx+1] for idx in range(self.label_len-1, len(orig_seq))] \\\n",
    "        if len(orig_seq) >= self.label_len else []\n",
    "        \n",
    "        self._check = dict((''.join(element[:-1]), element[-1]) for element in self.ptable.index.tolist())\n",
    "\n",
    "        new = list(orig_seq)\n",
    "        output = []\n",
    "        for idx,s in enumerate(seqs, 1):\n",
    "            flag = self._check.get(s)\n",
    "            if flag:\n",
    "                output.append((idx,flag))\n",
    "                new[idx] = flag\n",
    "        new = ''.join(new)\n",
    "\n",
    "        return (new, output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def viterbi_ng(seq, par, show=0):\n",
    "    # LM,NCM required\n",
    "    para = par.get('lmNcm_weight', None)\n",
    "    ng_num = par.get('ngnum', None)\n",
    "    \n",
    "    case = CASE(seq, ncm)\n",
    "    \n",
    "#     sect_named = namedtuple('sect_stat', 'score, length, idx, seq')\n",
    "    \n",
    "    cands4all =[]\n",
    "    pre_cand_lst = []\n",
    "    \n",
    "    for cur_idx, cur_ch in enumerate(case.query):  \n",
    "        section = []\n",
    "        if show==1:\n",
    "            print('==========')\n",
    "            print(cur_idx, cur_ch, ' '.join([x[0] for x in case.cands[cur_idx]]))        \n",
    "\n",
    "        if cur_idx==0 and cur_ch=='<s>':\n",
    "            section.append({'from_to':'<s>', 'score':0.0, 'seq':['<s>'], 'idx_seq':[0]})\n",
    "\n",
    "        elif cur_idx>0:                \n",
    "            # cand:[0] for cand_ch, [1] for cand_prob\n",
    "            for cand_idx, cand in enumerate(case.cands[cur_idx]):\n",
    "                # Add global \n",
    "                sect_ncm = math.log10(cand[1])              \n",
    "            \n",
    "                batch = []\n",
    "                \n",
    "                # lm.scoring(list)\n",
    "                for pre_idx, pre_cand in enumerate(pre_cand_lst):\n",
    "                    batch_seq = pre_cand['seq'] + [cand[0]]\n",
    "                    \n",
    "                    # Compute before?\n",
    "                    batch_lm = lm.scoring(batch_seq[-ng_num:], ng_num) + pre_cand['score']\n",
    "                    batch_score = (para[0] * batch_lm + para[1] * sect_ncm)\n",
    "                    \n",
    "                    if show==1: \n",
    "                        print('Seq:%s\\tpre:%.2f\\tbLM:%.2f\\tNCM:%.2f\\tTotal:%.2f' \\\n",
    "                              %(batch_seq[-ng_num:], pre_cand['score'], batch_lm, sect_ncm, batch_score))\n",
    "                    \n",
    "                    ttt = list(pre_cand['idx_seq'])                    \n",
    "                    ttt.append(cand_idx)\n",
    "                \n",
    "                    batch_dict = {'from_to':batch_seq[-ng_num:], 'score':batch_score, \\\n",
    "                                  'seq':batch_seq, 'idx_seq':ttt}\n",
    "                    \n",
    "                    batch.append(batch_dict)               \n",
    "                \n",
    "                best = max(batch, key=lambda x:x['score'])\n",
    "                if show==1: \n",
    "                    print('== Choose Seq:%s\\t NCM:%.2f\\tTotal:%.2f'\\\n",
    "                         %(best['from_to'], sect_ncm, best['score']))\n",
    "                                \n",
    "                section.append(best)\n",
    "                \n",
    "        pre_cand_lst = list(section)\n",
    "        cands4all.append(pre_cand_lst)\n",
    "    \n",
    "    winner = max(pre_cand_lst, key=lambda x:x['score'])\n",
    "    output = ''.join(winner['seq'][1:-1])\n",
    "        \n",
    "    result = dict(orig=seq, correct=output, log=cands4all, win=winner, cor_idx=winner['idx_seq'][1:-1])    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_test(testfilename, resultname, par):    \n",
    "    show = par.get('show',0)\n",
    "    \n",
    "    with open(testfilename, 'r',encoding='utf8') as fp, open(resultname,'w',encoding='utf8') as wp:\n",
    "        for line in fp:        \n",
    "            line = line.strip('\\n')\n",
    "            idx1 = line.find('=')+1\n",
    "            idx2 = line.find(')')\n",
    "            dataNum = line[idx1:idx2]\n",
    "            seq = line[idx2+2:]        \n",
    "\n",
    "            if show==1: print('=====')\n",
    "            print(dataNum)   \n",
    "            \n",
    "            errors = batch(seq, par)\n",
    "            \n",
    "            wp.write(dataNum)\n",
    "            if len(errors)!=0:\n",
    "                for error in errors:\n",
    "                    wp.write(', ')\n",
    "                    wp.write(', '.join(error))\n",
    "            else:\n",
    "                wp.write(', 0')\n",
    "                \n",
    "            wp.write('\\n')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def debug_ncm(ch, append=None, value= 0.05, show=0):    \n",
    "    tt = ncm.get_cands(ch)\n",
    "    if show==1:\n",
    "        for d in tt:\n",
    "            print(d)\n",
    "        \n",
    "    if append:\n",
    "        ncm.table[ch][append] = value\n",
    "        if show==1:\n",
    "            print('== Add %s to Set of %s' %(append,ch))\n",
    "    else:\n",
    "        return tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def debug_lm(seq, ngnum=2):\n",
    "    lst = seq.split()\n",
    "    for item in lst:\n",
    "        print(item, lm.scoring(item, ngnum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seperateSeq(seq):\n",
    "    pattern = re.compile('[，。！]')\n",
    "    \n",
    "    pre_idx=0\n",
    "    output = []\n",
    "    for idx, ch in enumerate(seq):\n",
    "        if pattern.search(ch):\n",
    "            tmp = seq[pre_idx:idx+1]\n",
    "            output.append(tmp)\n",
    "            pre_idx = idx+1\n",
    "    \n",
    "    if pre_idx<len(seq):\n",
    "        tmp = seq[pre_idx:idx+1]\n",
    "        output.append(tmp)\n",
    "        \n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch(seq, par = {\n",
    "        'lmNcm_weight':[0.7,0.3],\n",
    "        'ngnum':3,\n",
    "        'pre_con':True,\n",
    "        'con_log_file':'special_case4con.txt',\n",
    "        'show':0        \n",
    "    }, show=0):            \n",
    "    \n",
    "    con_log_file = par.get('con_log_file', 'special_case4con.txt')\n",
    "    \n",
    "    sub_seqs = seperateSeq(seq)\n",
    "    \n",
    "    total_length = 0\n",
    "    error_dict = dict()\n",
    "    for sub in sub_seqs:\n",
    "        if show==1: \n",
    "            print('pre:', sub, len(sub))\n",
    "        '''\n",
    "        Preprocess\n",
    "        '''\n",
    "        if par.get('pre_con',False):\n",
    "            (sub, output) = con_preprocess.scan(sub)\n",
    "            if len(output)>0: \n",
    "                with open(con_log_file,'a',encoding='utf8') as wp:\n",
    "                    wp.write(sub)\n",
    "                    for (idx,ch) in output:\n",
    "                        wp.write('{}\\t{}\\t'.format(str(idx),ch))\n",
    "                    wp.write('\\n')\n",
    "            con_dict = dict((str(idx+total_length+1), ch) for idx,ch in output)\n",
    "            error_dict.update(con_dict)\n",
    "        \n",
    "        '''\n",
    "        Viterbi\n",
    "        '''\n",
    "        if show==1: print(sub)\n",
    "        result = viterbi_ng(sub, par, show)\n",
    "        tmp_pos   = [i for i,e in enumerate(result['cor_idx']) if e!=0]\n",
    "        pos_error = [str(idx+total_length+1) for idx in tmp_pos]     \n",
    "        ch_error  = [result['correct'][int(idx)] for idx in tmp_pos]\n",
    "        \n",
    "        if show==1:\n",
    "            for idx in tmp_pos:\n",
    "                print(result['correct'][int(idx)])\n",
    "            print(result['orig'])\n",
    "            print(result['correct'])  \n",
    "        \n",
    "        viter_dict = dict((p,s) for p,s in zip(pos_error, ch_error))\n",
    "        error_dict.update(viter_dict)\n",
    "        \n",
    "        '''\n",
    "        End\n",
    "        '''\n",
    "        total_length += len(sub)\n",
    "        \n",
    "    return sorted(error_dict.items(), key=lambda x:int(x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "debug_lm('市占率 視障率')\n",
    "\n",
    "lm.scoring('市占率',show=1)\n",
    "\n",
    "lm.scoring('視障率',show=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading language model G:/UDN/training_confusion/sinica.corpus.seg.char.lm ...\n",
      "Loading channel model G:/UDN/training_confusion/channelModel.pkl ...\n",
      "Loading Preprocess_RuleBased model ./extractUDN_prepost/all.csv ...\n"
     ]
    }
   ],
   "source": [
    "lm = LM(lm_filename)\n",
    "ncm = NCM(channel_filename)\n",
    "con_preprocess = CONFUSION(con_filename, con_log_file='special_case4con.txt')\n",
    "con_preprocess.organize(label=['pre','error','corr'], threshold=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def t1(sys, par):\n",
    "    if len(sys.argv) < 3:\n",
    "        print('Usage: python filename.py token test_file1')\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        token     = sys.argv[1]\n",
    "        test_data = sys.argv[2]\n",
    "        \n",
    "        ncm_insert_vals = [0.005,0.01,0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85]\n",
    "\n",
    "        for ncm_insert_val in ncm_insert_vals:\n",
    "            result_name = './test_15/re_{}_{}.txt'.format\n",
    "            ncm_tag = str(ncm_insert_val)[2:]\n",
    "            \n",
    "#             del ncm\n",
    "            channel_filename = './confusionAdd/confusionSet_{}.pkl'.format(ncm_tag)\n",
    "            ncm = NCM(channel_filename)\n",
    "\n",
    "            run_test(test_data, result_name(token, ncm_tag), par)\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def t2(sys, par):\n",
    "    global ncm\n",
    "    if len(sys.argv) < 3:\n",
    "        print('Usage: python filename.py token channel_model test_data')\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        token     = sys.argv[1]\n",
    "        channel_model = sys.argv[2]\n",
    "        test_data = sys.argv[3]\n",
    "        \n",
    "        del ncm\n",
    "        \n",
    "        ncm = NCM(channel_model)\n",
    "        \n",
    "        result_name = './test_15/re_{}.txt'.format\n",
    "               \n",
    "        run_test(test_data, result_name(token), par)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def t3(sys, par):\n",
    "    global lm\n",
    "    if len(sys.argv) < 4:\n",
    "        print('Usage: python filename.py token language_model test_data ngram')\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        token     = sys.argv[1]\n",
    "        language_model = sys.argv[2]\n",
    "        test_data = sys.argv[3]\n",
    "        par['ngnum'] = int(sys.argv[4])\n",
    "        \n",
    "        del lm \n",
    "        \n",
    "        lm = LM(language_model)\n",
    "        \n",
    "        result_name = './test_15/re_{}.txt'.format\n",
    "        run_test(test_data, result_name(token), par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def t4(sys, par):\n",
    "    global ncm\n",
    "    if len(sys.argv) < 4:\n",
    "        print('Usage: python filename.py token ncm_global channel_model test_data ')\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        token = sys.argv[1]\n",
    "        ncm_global = sys.argv[2]\n",
    "        channel_model = sys.argv[3]\n",
    "        test_data = sys.argv[4]\n",
    "        \n",
    "        del ncm\n",
    "        \n",
    "        ncm = NCM(channel_model, ncm_global)\n",
    "        \n",
    "        result_name = './test_15/re_{}.txt'.format\n",
    "               \n",
    "        run_test(test_data, result_name(token), par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    par = {\n",
    "        'lmNcm_weight':[0.7,0.3],\n",
    "        'ngnum':3,\n",
    "        'pre_con':False,\n",
    "        'con_log_file':'special_case4con.txt',        \n",
    "        'show':0\n",
    "    }\n",
    "    \n",
    "    t4(sys,par)\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
