{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import requests\n",
    "import os \n",
    "import pickle\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import socket\n",
    "import xml.etree.ElementTree as ET\n",
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "from model.model import LM, CASE, NCM, CKIP\n",
    "\n",
    "import time \n",
    "import sys, getopt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_root = '/home/kiwi/udn_data/training_confusion/'\n",
    "# data_root = 'G:/UDN/training_confusion/'\n",
    "\n",
    "if os.environ.get('USERDOMAIN') == 'KIWI-PC':\n",
    "    data_root = 'G:/UDN/training_confusion/'\n",
    "else:\n",
    "    data_root = '/home/kiwi/udn_data/training_confusion/'\n",
    "\n",
    "channel_filename = data_root+'channelModel.pkl'\n",
    "lm_filename = data_root+'sinica.corpus.seg.char.lm'\n",
    "con_filename = './extractUDN_prepost/all.csv'\n",
    "\n",
    "# candsExpand = CANDSEXPAND(ncmEx_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CONFUSION:\n",
    "    def __init__(self, filename, con_log_file):\n",
    "        print('Loading Preprocess_RuleBased model {} ...'.format(filename))\n",
    "        self.df = pd.DataFrame.from_csv(con_filename)\n",
    "        if os.path.exists(con_log_file):\n",
    "            os.remove(con_log_file)\n",
    "    \n",
    "    def organize(self, label=[], threshold=10):\n",
    "        if set(label).issubset(set(self.df)) and len(label)>0:\n",
    "            self.ptable = self.df.groupby(label)\n",
    "        else:\n",
    "            label = ['pre','error','post','corr']\n",
    "            self.ptable = self.df.groupby(label)\n",
    "            \n",
    "        self.ptable = self.speDataframe(self.ptable)\n",
    "        self.ptable = self.ptable.loc[self.ptable['count']>threshold]\n",
    "        self.label_len = len(label)-1\n",
    "        \n",
    "    def speDataframe(self,_gg):\n",
    "        _ggS = _gg.size()\n",
    "        _ggDF = pd.DataFrame(_ggS,columns=['count'])\n",
    "        _ggDF_sort = _ggDF.sort_values('count', ascending=False)\n",
    "\n",
    "        return _ggDF_sort\n",
    "    \n",
    "    def scan(self, orig_seq='這邊的空氣污染很嚴重的市佔率'):\n",
    "        # Consider the length of new lable\n",
    "        \n",
    "        seqs = [orig_seq[idx-(self.label_len-1):idx+1] for idx in range(self.label_len-1, len(orig_seq))] \\\n",
    "        if len(orig_seq) >= self.label_len else []\n",
    "        \n",
    "        self._check = dict((''.join(element[:-1]), element[-1]) for element in self.ptable.index.tolist())\n",
    "\n",
    "        new = list(orig_seq)\n",
    "        output = []\n",
    "        for idx,s in enumerate(seqs, 1):\n",
    "            flag = self._check.get(s)\n",
    "            if flag:\n",
    "                output.append((idx,flag))\n",
    "                new[idx] = flag\n",
    "        new = ''.join(new)\n",
    "\n",
    "        return (new, output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "花村 的 地途/-10.92\t花村的地圖/-14.31\n",
      "花村 的 地圖/-11.34\t花村的在途/-16.30\n",
      "花村 的 在 途/-14.56\t花村的的途/-16.50\n",
      "花村 的 的 途/-14.72\t花村的在圖/-17.36\n",
      "花村 的 在 圖/-15.34\t花村的的圖/-17.64\n",
      "花村 的 的 圖/-15.84\t華村的在途/-17.82\n",
      "花村 的 的 塗/-16.53\t花村等的途/-17.83\n",
      "花村 的 的 徒/-17.12\t花村的的塗/-17.86\n",
      "花村 地 在 途/-17.21\t花村學的途/-17.90\n",
      "花村 等 的 途/-17.27\t花村的的徒/-17.95\n",
      "花村 等 在 途/-17.82\t華村的的途/-18.02\n",
      "花村 學 的 途/-18.09\t家村的在途/-18.04\n",
      "花村 特 在 途/-19.91\t花村的地途/-18.04\n",
      "花村 特 的 途/-20.06\t花村地在途/-18.12\n",
      "花村地 的 途/-20.24\t花村地的途/-18.17\n",
      "華村 的 在 途/-22.60\t家村的的途/-18.23\n",
      "家村 的 在 途/-22.60\t花村等在途/-18.24\n",
      "化村 的 在 途/-22.60\t花村特的途/-18.30\n",
      "華村 的 的 途/-22.76\t化村的在途/-18.50\n",
      "家村 的 的 途/-22.76\t花村特在途/-18.52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(['花村', '的', '地圖'], -14.308096455515043, -11.343616613008853),\n",
       " (['花村', '的', '地途'], -18.043678888260054, -10.924251890999999),\n",
       " (['花村', '的', '在', '途'], -16.30411656551504, -14.56056035129005)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reRanking(candidates, origSeq, par):\n",
    "    WEIGHT = par.get('WEIGHT', 0.7)\n",
    "    NGNUM = par.get('NGNUM', 3)\n",
    "    SEGMETHOD, LMMETHOD = par.get('RERANK', ['CKIP', 'ALL'])\n",
    "    CKIPACCOUNT = par.get('CKIP',{'username':'sean2249','password':'3345678'})\n",
    "    WORDPORT = par.get('WORDPORT', 5488)\n",
    "    SHOW = par.get('SHOW', 1)\n",
    "\n",
    "    ckip = CKIP(**CKIPACCOUNT)\n",
    "\n",
    "    lm_get = 'http://140.112.91.62:{}/api/{}{}'.format\n",
    "    re_candidates = []\n",
    "    for (cand, chScore,_) in candidates:\n",
    "        candSeq = ''.join(cand[1:-1])\n",
    "\n",
    "        if SEGMETHOD == 'JIEBA':\n",
    "            candSeg = list(jieba.cut(candSeq))\n",
    "        elif SEGMETHOD == 'CKIP':    \n",
    "            candSeg = list(ckip.cut(candSeq))\n",
    "\n",
    "        ncmScore = 0.0\n",
    "        for o, c in zip(origSeq, candSeq):\n",
    "            if o != c:\n",
    "                try:\n",
    "                    ncmScore += math.log10(ncm.table[o][c])\n",
    "                except:\n",
    "                    print(o,c)\n",
    "                    print(origSeq, candSeq)\n",
    "                    raise RuntimeError('ass')\n",
    "\n",
    "        # Language model\n",
    "        if LMMETHOD == 'ELEMENT':\n",
    "            wordLM = 0\n",
    "            for item in candSeg:\n",
    "                i = [item]\n",
    "                wordLM += requests.get(lm_get(WORDPORT, NGNUM, '||'.join(i))).json()['score']\n",
    "        elif LMMETHOD == 'ALL':\n",
    "            wordLM = requests.get(lm_get(WORDPORT, NGNUM, '||'.join(candSeg))).json()['score']    \n",
    "\n",
    "        wordScore = wordLM*WEIGHT + ncmScore*(1-WEIGHT)\n",
    "\n",
    "        re_candidates.append((candSeg, chScore, wordScore))\n",
    "\n",
    "    \n",
    "    if SHOW == 1:        \n",
    "        wordCands = sorted(re_candidates, key= lambda x:x[2], reverse=True)\n",
    "        chCands = sorted(re_candidates, key= lambda x:x[1], reverse=True)\n",
    "        for w,c in zip(wordCands, chCands):\n",
    "            print('{}/{:.2f}\\t{}/{:.2f}'.format(' '.join(w[0]), w[2], ''.join(c[0]), c[1]))\n",
    "        \n",
    "    return sorted(re_candidates, key= lambda x:x[1]+x[2], reverse=True)[:3]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def beamSearch(seq, par):\n",
    "    \n",
    "    SHOW = par.get('SHOW', 1)\n",
    "    NGNUM = par.get('NGNUM', 3)\n",
    "    WEIGHT = par.get('WEIGHT', 0.7)\n",
    "    PRUNE_LIMIT = par.get('BATCH',[0, 20])[1]\n",
    "    CHARPORT = par.get('CHARPORT', 5487)     \n",
    "    \n",
    "    lm_get = 'http://140.112.91.62:{}/api/{}{}'.format\n",
    "    case = CASE(seq, ncm)    \n",
    "    \n",
    "    case.query[-1] = '<s>'\n",
    "    stack = [(case.query, requests.get(lm_get(CHARPORT, NGNUM, '||'.join(case.query))).json()['score'], 0)]\n",
    "    \n",
    "    for cur_idx, cur_ch in enumerate(case.query):\n",
    "        batch = []\n",
    "        \n",
    "        if SHOW==1:\n",
    "            print('========')            \n",
    "            print(cur_idx, ' '.join([x[0] for x in case.cands[cur_idx]]))\n",
    "             \n",
    "        for (cand, cand_prob) in case.cands[cur_idx]:                                        \n",
    "            cand_ncm = math.log10(cand_prob)\n",
    "\n",
    "            for cur_seq, orig_score, orig_ncm in stack:                   \n",
    "                sect_seq = list(cur_seq)\n",
    "                sect_seq[cur_idx] = cand\n",
    "                \n",
    "                if sect_seq[-1] == '</s>':\n",
    "                        sect_seq[-1] = '<s>'\n",
    "                try:\n",
    "                    sect_lm = requests.get(lm_get(CHARPORT, NGNUM, '||'.join(sect_seq))).json()['score']\n",
    "                except:\n",
    "                    print('ERROR')\n",
    "                    return \n",
    "                \n",
    "                sect_ncm = orig_ncm + cand_ncm\n",
    "\n",
    "                sect_score = (sect_lm*WEIGHT) + (sect_ncm*(1-WEIGHT))\n",
    "                \n",
    "                batch.append((sect_seq, sect_score, sect_ncm))\n",
    "\n",
    "        stack = sorted(batch, key= lambda x:x[1], reverse=True)[:PRUNE_LIMIT]\n",
    "            \n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def viterbi(seq, par):\n",
    "    SHOW = par.get('SHOW', 1)\n",
    "    NGNUM = par.get('NGNUM', 3)\n",
    "    WEIGHT = par.get('WEIGHT', 0.7)\n",
    "    LMMETHOD = par.get('BATCH',[0, 'ELEMENT'])[1]\n",
    "    CHARPORT = par.get('CHARPORT', 5487)        \n",
    "    \n",
    "    # lm http    \n",
    "    lm_get = 'http://140.112.91.62:{}/api/{}{}'.format        \n",
    "    \n",
    "    case = CASE(seq, ncm)\n",
    "    \n",
    "    for cur_idx, cur_ch in enumerate(case.query):  \n",
    "        if SHOW==1:\n",
    "            print('==========')\n",
    "            print(cur_idx, ' '.join([x[0] for x in case.cands[cur_idx]]))        \n",
    "\n",
    "        if cur_idx==0:\n",
    "            section = [(['<s>'], 0.0, 0)]\n",
    "                            \n",
    "        else:\n",
    "            tmp_section = []\n",
    "            for (cand, cand_prob) in case.cands[cur_idx]:\n",
    "                cand_ncm = math.log10(cand_prob)\n",
    "                batch = []\n",
    "                for (pre_seq, pre_score, pre_ncm) in section:\n",
    "                    batch_seq = list(pre_seq)\n",
    "                    batch_seq.append(cand)\n",
    "                    \n",
    "                    if batch_seq[-1] == '</s>':\n",
    "                        batch_seq[-1] = '<s>'\n",
    "                        \n",
    "                    lmSeq = batch_seq if LMMETHOD == 'ALL' else batch_seq[-NGNUM:]\n",
    "                    \n",
    "                    try:\n",
    "                        batch_lm = (requests.get(\n",
    "                            lm_get(CHARPORT, NGNUM, '||'.join(lmSeq))).json()['score'])\n",
    "                    except:\n",
    "                        print(batch_seq)\n",
    "                        print(lm_get(CHARPORT, NGNUM, '||'.join(batch_seq)))\n",
    "                        return \n",
    "                    \n",
    "                    batch_ncm = pre_ncm + cand_ncm\n",
    "                    batch_score = batch_lm * WEIGHT + cand_ncm * (1-WEIGHT) + pre_score\n",
    "                    \n",
    "                    batch.append((batch_seq, batch_score, batch_ncm))\n",
    "                    \n",
    "                winner = max(batch, key=lambda x:x[1])\n",
    "                if SHOW ==1:\n",
    "                    print('{}  {}'.format(cand, winner[0]))\n",
    "                tmp_section.append(winner)\n",
    "                \n",
    "            section = list(tmp_section)     \n",
    "    \n",
    "    \n",
    "    sub = section[0][0]\n",
    "    return ''.join(sub[1:-1])\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_test(testfilename, resultname, par):    \n",
    "    show = par.get('SHOW',0)\n",
    "    \n",
    "    with open(testfilename, 'r',encoding='utf8') as fp, open(resultname,'w',encoding='utf8') as wp:\n",
    "        for line in fp:        \n",
    "            line = line.strip('\\n')\n",
    "            idx1 = line.find('=')+1\n",
    "            idx2 = line.find(')')\n",
    "            dataNum = line[idx1:idx2]\n",
    "            seq = line[idx2+2:]        \n",
    "\n",
    "            if show==1: print('=====')\n",
    "            print(dataNum)   \n",
    "            \n",
    "            errors = batch(seq, par)\n",
    "            \n",
    "            wp.write(dataNum)\n",
    "            if len(errors)!=0:\n",
    "                for error in errors:\n",
    "                    wp.write(', ')\n",
    "                    wp.write(', '.join(error))\n",
    "            else:\n",
    "                wp.write(', 0')\n",
    "                \n",
    "            wp.write('\\n')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def debug_ncm(ch, append=None, value= 0.05, show=0):    \n",
    "    tt = ncm.get_cands(ch)\n",
    "    if show==1:\n",
    "        for d in tt:\n",
    "            print(d)\n",
    "        \n",
    "    if append:\n",
    "        ncm.table[ch][append] = value\n",
    "        if show==1:\n",
    "            print('== Add %s to Set of %s' %(append,ch))\n",
    "    else:\n",
    "        return tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def debug_lm(seq, ngnum=2):\n",
    "    lst = seq.split()\n",
    "    for item in lst:\n",
    "        print(item, lm.scoring(item, ngnum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seperateSeq(seq):\n",
    "    pattern = re.compile('[，。！；]')\n",
    "    \n",
    "    pre_idx=0\n",
    "    output = []\n",
    "    for idx, ch in enumerate(seq):\n",
    "        if pattern.search(ch):\n",
    "            tmp = seq[pre_idx:idx+1]\n",
    "            output.append(tmp)\n",
    "            pre_idx = idx+1\n",
    "    \n",
    "    if pre_idx<len(seq):\n",
    "        tmp = seq[pre_idx:idx+1]\n",
    "        output.append(tmp)\n",
    "        \n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch(seq, par):\n",
    "    SHOW = par.get('SHOW', 1)\n",
    "    PRE  = par.get('PRE', False)\n",
    "    METHOD = par.get('BATCH', ['BEAM','ALL'])[0]\n",
    "    \n",
    "    \n",
    "    con_log_file = par.get('con_log_file', 'special_case4con.txt')\n",
    "    \n",
    "    sub_seqs = seperateSeq(seq)\n",
    "    \n",
    "    total_length = 0\n",
    "    error_dict = dict()\n",
    "    for orig in sub_seqs:\n",
    "        if SHOW==1: \n",
    "            print('Original: {}'.format(orig))\n",
    "        '''\n",
    "        Preprocess\n",
    "        '''\n",
    "        sub = str(orig)\n",
    "        if PRE:\n",
    "            (sub, errors) = con_preprocess.scan(orig)\n",
    "            erros = dict((str(idx+total_length+1), ch) for idx, ch in errors)\n",
    "            errro_dict.update(errors)\n",
    "            if SHOW == 1:\n",
    "                print('Pre: {}'.format(sub))                \n",
    "            \n",
    "        if METHOD == 'VITERBI':\n",
    "            \n",
    "            sub = viterbi(sub, par)\n",
    "            if SHOW == 1:\n",
    "                print('Viterbi: {}'.format(sub))\n",
    "                \n",
    "        elif METHOD == 'BEAM':\n",
    "            candidates = beamSearch(sub, par)\n",
    "            sub = reRanking(candidates, orig, par)[0][0]\n",
    "            sub = ''.join(sub)\n",
    "            if SHOW == 1:\n",
    "                print('Beam: {}'.format(sub))\n",
    "            \n",
    "        errors = dict((str(idx+total_length+1), s) \n",
    "              for idx, (o, s) in enumerate(zip(orig, sub)) if o != s)            \n",
    "        error_dict.update(errors)                                    \n",
    "        total_length += len(sub)\n",
    "        \n",
    "        print(sub)\n",
    "        \n",
    "    return sorted(error_dict.items(), key=lambda x:int(x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "debug_lm('市占率 視障率')\n",
    "\n",
    "lm.scoring('市占率',show=1)\n",
    "\n",
    "lm.scoring('視障率',show=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-13-bafb982a0106>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-bafb982a0106>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    def create(self, sentence, ncm):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class CASE:\n",
    "    def __init__(self, word_filename):\n",
    "    \n",
    "#     def __init__(self, sentence, ncm):\n",
    "    def create(self, sentence, ncm):\n",
    "        assert type(sentence) == str, 'Input must be string'\n",
    "        assert len(sentence) > 0, 'Input must have content'\n",
    "        self.query=[]\n",
    "        self.query.append('<s>')\n",
    "        self.query.extend(list(sentence))\n",
    "        self.query.append('<s>')\n",
    "            \n",
    "        # get candidate\n",
    "        self.cands = []\n",
    "        for cur_ch in self.query:\n",
    "            self.cands.append(ncm.get_cands(cur_ch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4745c5f9156d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_filename' is not defined"
     ]
    }
   ],
   "source": [
    "with open(word_filename, 'r', encoding='utf8') as fp:\n",
    "    line = fp.readlines()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_dict = []\n",
    "for l in line:\n",
    "    if not re.findall(r'\\{', l) and re.findall(r'[a-zA-Z]', l):\n",
    "        word_dict.append(l.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = [(w,len(w)) for w in word_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tt = sorted(t, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = tt[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'聖多美及普林西比民主共和國（Democratic Republic of Sao Tome and Principt）'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'[a-zA-Z]', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147659"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{[8e41]}\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\{', line[2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if _:\n",
    "    print('d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = 0 \n",
    "for idx, l in enumerate(line[:141123]):\n",
    "    if re.findall(r'\\{', l):\n",
    "        m = max(m, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136131"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141124"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_filename = data_root + 'dict_word.txt'\n",
    "# ref_word = CASE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading channel model ./confusionTable/confu_999995_9_50.pkl ...\n"
     ]
    }
   ],
   "source": [
    "# lm = LM(lm_filename)\n",
    "# ncm = NCM(channel_filename)\n",
    "ncm = NCM('./confusionTable/confu_999995_9_50.pkl')\n",
    "# con_preprocess = CONFUSION(con_filename, con_log_file='special_case4con.txt')\n",
    "# con_preprocess.organize(label=['pre','error','corr'], threshold=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_command():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--token', required=True)\n",
    "    parser.add_argument('--test', required=True)\n",
    "    \n",
    "    parser.add_argument('--lm', default=0)\n",
    "    parser.add_argument('--ngnum', type=int, default=2)\n",
    "    \n",
    "    parser.add_argument('--ncm', default=0)\n",
    "    \n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(args, par):\n",
    "    result_name = './test_15/re_{}.txt'.format\n",
    "    \n",
    "    if args.lm != 0:\n",
    "        del lm \n",
    "        lm = LM(args.lm)\n",
    "    if args.ncm != 0:\n",
    "        del ncm\n",
    "        ncm = NCM(args.ncm)\n",
    "    \n",
    "    \n",
    "    par['ngnum'] = args.ngnum\n",
    "    \n",
    "    \n",
    "    run_test(args.test, result_name(args.token), par)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def t1(sys, par):\n",
    "    if len(sys.argv) < 3:\n",
    "        print('Usage: python filename.py token test_file1')\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        token     = sys.argv[1]\n",
    "        test_data = sys.argv[2]\n",
    "        \n",
    "        ncm_insert_vals = [0.005,0.01,0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85]\n",
    "\n",
    "        for ncm_insert_val in ncm_insert_vals:\n",
    "            result_name = './test_15/re_{}_{}.txt'.format\n",
    "            ncm_tag = str(ncm_insert_val)[2:]\n",
    "            \n",
    "#             del ncm\n",
    "            channel_filename = './confusionAdd/confusionSet_{}.pkl'.format(ncm_tag)\n",
    "            ncm = NCM(channel_filename)\n",
    "\n",
    "            run_test(test_data, result_name(token, ncm_tag), par)\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def t2(sys, par):\n",
    "    global ncm\n",
    "    if len(sys.argv) < 3:\n",
    "        print('Usage: python filename.py token channel_model test_data')\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        token     = sys.argv[1]\n",
    "        channel_model = sys.argv[2]\n",
    "        test_data = sys.argv[3]\n",
    "        \n",
    "        del ncm\n",
    "        \n",
    "        ncm = NCM(channel_model)\n",
    "        \n",
    "        result_name = './test_15/re_{}.txt'.format\n",
    "               \n",
    "        run_test(test_data, result_name(token), par)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def t3(sys, par):\n",
    "    global lm\n",
    "    if len(sys.argv) < 4:\n",
    "        print('Usage: python filename.py token language_model test_data ngram')\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        token     = sys.argv[1]\n",
    "        language_model = sys.argv[2]\n",
    "        test_data = sys.argv[3]\n",
    "        par['ngnum'] = int(sys.argv[4])\n",
    "        \n",
    "        del lm \n",
    "        \n",
    "        lm = LM(language_model)\n",
    "        \n",
    "        result_name = './test_15/re_{}.txt'.format\n",
    "        run_test(test_data, result_name(token), par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def t4(sys, par):\n",
    "    global ncm\n",
    "    if len(sys.argv) < 4:\n",
    "        print('Usage: python filename.py token ncm_global channel_model test_data ')\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        token = sys.argv[1]\n",
    "        ncm_global = sys.argv[2]\n",
    "        channel_model = sys.argv[3]\n",
    "        test_data = sys.argv[4]\n",
    "        \n",
    "        del ncm\n",
    "        \n",
    "        ncm = NCM(channel_model, ncm_global)\n",
    "        \n",
    "        result_name = './test_15/re_{}.txt'.format\n",
    "               \n",
    "        run_test(test_data, result_name(token), par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    #     args = process_command()\n",
    "    par = {\n",
    "        'WORDPORT':5488,\n",
    "        'CHARPORT':5487,        \n",
    "        'PRE':False,\n",
    "        'NGNUM':3,\n",
    "        'WEIGHT':0.7,\n",
    "        # [viterbi, all/element]\n",
    "        # [beam, prune_limit]\n",
    "        'BATCH':['VITERBI', 'ALL'], \n",
    "        # CKIP/JIEBA ALL/ELEMENT\n",
    "        'RERANK':[\n",
    "            'CKIP','ALL'],\n",
    "        'CKIP':{'username':'sean2249', 'password':'3345678'}\n",
    "        'SHOW':0                \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 已經有別於已往，\n",
      "已經有別於以往，\n",
      "已經有別於以往，\n",
      "已經有別於以往，\n",
      "已經有別於以往，\n",
      "1 聯合國世界銀行國際金融公司與英國金融時報於台北時間今天清晨宣布新北市獲得「城市轉型卓越奬」，\n",
      "聯合國世界銀行國際金融公司與英國金融時報於台北時間今天清晨宣布新北市獲得「城市轉型作越奬」，\n",
      "聯合國世界銀行國際金融公司與英國金融時報於台北時間今天清晨宣布新北市獲得「城市轉型作越奬」，\n",
      "聯合國世界銀行國際金融公司與英國金融時報於台北時間今天清晨宣布新北市獲得「城市轉型卓越?\n",
      "聯合國世界銀行國際金融公司與英國金融時報於台北時間今天清晨宣布新北市獲得「城市轉型卓越?\n",
      "2 未能激起配偶性慾是女性最常犯的大錯之一。\n",
      "未能激起配偶性慾是女性最常犯的大錯之一。\n",
      "未能激起配偶性慾是女性最常犯的大錯之一。\n",
      "為能激起配偶性慾是女性最常犯的大錯之一。\n",
      "未能激起配偶性慾是女性最常犯的大錯之一。\n",
      "3 「林右昌在基層很紮實、實在，\n",
      "「林右昌在基層很紮實、實在，\n",
      "「林右昌在基層很紮實、實在，\n",
      "「林右昌在基層很紮實、實在，\n",
      "「林右昌在基層很紮實、實在，\n",
      "4 不要讓學生覺得沒唸書也會及格，\n",
      "不要讓學生覺得沒唸書也會及格，\n",
      "不要讓學生覺得沒唸書也會及格，\n",
      "不要讓學生覺得沒唸書也會及格，\n",
      "不要讓學生覺得沒唸書也會及格，\n",
      "5 目前委託台灣大學資工系副教授廖世偉協助瞭解是否有機會可以做成。\n",
      "目前委託台灣大學資工系副教授廖世偉協助了解是否有機會可以做成。\n",
      "目前委託台灣大學資工系副教授廖世偉協助了解是否有機會可以做成。\n",
      "目前委託台灣大學資工系副教授廖世偉協助了解是否有機會可以做成。\n",
      "目前委託台灣大學資工系副教授廖世偉協助了解是否有機會可以做成。\n",
      "6 區塊鏈系統也兩大特色，\n",
      "區塊鏈系統也兩大特色，\n",
      "區塊鏈系統也兩大特色，\n",
      "區塊鏈系統也兩大特色，\n",
      "區面鏈系統也兩大特色，\n",
      "7 青創先峰匯旨在為兩岸青年搭建平台切磋，\n",
      "青創先鋒會指在為兩岸青年踏建平台設磋，\n",
      "青創先鋒會指在為兩岸青年踏建平台設磋，\n",
      "青創先風會指在為兩岸青年搭建平台切磋，\n",
      "青創天峰會指在為兩岸青年搭建平台切磋，\n",
      "8 規劃保險時，\n",
      "規劃保險時，\n",
      "規劃保險時，\n",
      "規劃保險時，\n",
      "規劃保險時，\n"
     ]
    }
   ],
   "source": [
    "# seq = '幸虧我會說德問'\n",
    "# seq = '因為他很用功常常坐最'\n",
    "# seq = '花村的地途'\n",
    "seq = '能利用積木作出機器人的結構，'\n",
    "seqs = [\n",
    "    '已經有別於已往，', #(以)\n",
    "    '聯合國世界銀行國際金融公司與英國金融時報於台北時間今天清晨宣布新北市獲得「城市轉型卓越奬」，', #(獎)\n",
    "    '未能激起配偶性慾是女性最常犯的大錯之一。', #(欲)\n",
    "    '「林右昌在基層很紮實、實在，', #(扎)\n",
    "    '不要讓學生覺得沒唸書也會及格，', #(念)\n",
    "    '目前委託台灣大學資工系副教授廖世偉協助瞭解是否有機會可以做成。', #(了)\n",
    "    '區塊鏈系統也兩大特色，', #(有)\n",
    "    '青創先峰匯旨在為兩岸青年搭建平台切磋，', #(鋒)\n",
    "    '規劃保險時，', #(畫)\n",
    "]\n",
    "\n",
    "for idx, seq in enumerate(seqs):\n",
    "    print(idx, seq)\n",
    "    par = {'BATCH':['VITERBI','ALL'], 'SHOW':0}\n",
    "    batch(seq, par)\n",
    "    par = {'BATCH':['VITERBI','ELEMENT'], 'SHOW':0}\n",
    "    batch(seq, par)\n",
    "    par = {'BATCH':['BEAM', 20], 'RERANK':['CKIP','ALL'], 'SHOW':0}\n",
    "    batch(seq, par)\n",
    "    par = {'BATCH':['BEAM', 20], 'RERANK':['CKIP','ELEMENT'], 'SHOW':0}\n",
    "    batch(seq, par)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
