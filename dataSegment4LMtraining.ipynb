{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re \n",
    "import jieba\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def runUdnSegment(dataroot, outputfile, action, unwanted_ptn):\n",
    "    '''Extract UDN news, and ouput char-level segement file \n",
    "    \n",
    "    Need to revise pattern regular experission \n",
    "    \n",
    "    Args:\n",
    "        dataroot (str): the position of UDN news (recursive)\n",
    "        outputfile (str): the position of output file \n",
    "        action (dict): parameter for seperate and segmentation-level \n",
    "        unwanted_ptn (rgex): pattern for kicking unwanted character \n",
    "    Return: \n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    sep_method = action.get('sep_method', 'comma')\n",
    "    seg_level = action.get('seg_level', 'char')\n",
    "    \n",
    "    if os.path.exists(outputfile): \n",
    "        print('Clean %s' %(outputfile))\n",
    "        os.remove(outputfile)\n",
    "    \n",
    "    pattern = re.compile('TEXT')\n",
    "    \n",
    "    for dirPath, dirName, filelist in os.walk(dataroot, topdown=False):\n",
    "        if pattern.search(dirPath):        \n",
    "            print(dirPath)\n",
    "            for file in filelist:\n",
    "\n",
    "                inputfile = dirPath+'/'+file\n",
    "    #             print(inputfile)\n",
    "                with open(inputfile, 'rb') as fp:\n",
    "                    data = fp.read().decode('big5-hkscs', 'ignore')\n",
    "                    soup = BeautifulSoup(data, 'lxml')\n",
    "                    \n",
    "                content = contentExtract(soup)\n",
    "#                 seqs = seperateSeq(content, sep_method)\n",
    "#                 seqs_filter = filterSeq(seqs, unwanted_ptn)\n",
    "#                 seg_string = transformSeq(seqs_filter, seg_level)\n",
    "                seg_string = transformSeq(content, seg_level)\n",
    "\n",
    "                \n",
    "                with open(outputfile, 'a', encoding='utf8') as wp:\n",
    "                    wp.write(seg_string+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contentExtract(soup):\n",
    "    '''Extract the string content of website \n",
    "    Args:\n",
    "        soup (Beatutifulsoup): website \n",
    "    Return:\n",
    "        output (str): the string content of website\n",
    "    '''\n",
    "    output = ''\n",
    "    for pTxt in soup.find_all('p'):\n",
    "        res = ''\n",
    "        for tag_c in pTxt.contents:\n",
    "            try:\n",
    "                if tag_c.get('class')==1:\n",
    "                    res = res+tag_c.string\n",
    "            except:\n",
    "                res = res + tag_c\n",
    "        res = res.strip('.\\f\\n\\r\\t\\v')\n",
    "        if len(res)==0:\n",
    "            continue\n",
    "        output = output + res+'\\n'\n",
    "#         print(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def seperateSeq(content, sep_method):\n",
    "    '''Seperate string into sub-sentence\n",
    "    Args:\n",
    "        content (str): website content \n",
    "        sep_method (str): 'original' or 'comma'\n",
    "    Return:\n",
    "        output (list): sub-sentence\n",
    "    '''\n",
    "    output = []\n",
    "    if sep_method == 'comma':\n",
    "        pattern = re.compile('[，。！？]')\n",
    "        content = ''.join(content.split('\\n'))\n",
    "\n",
    "        pre_idx=0\n",
    "        for idx, ch in enumerate(content):\n",
    "            if pattern.search(ch):\n",
    "                tmp = content[pre_idx:idx+1]\n",
    "                output.append(tmp)\n",
    "                pre_idx = idx+1\n",
    "\n",
    "    #     print(pre_idx, len(seq))\n",
    "        if pre_idx<len(content):\n",
    "            tmp = content[pre_idx:len(content)]\n",
    "            output.append(tmp)\n",
    "    elif sep_method:\n",
    "        output = content.split('\\n')\n",
    "    \n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterSeq(lst, pattern):\n",
    "    '''Filter unwanted sequence based on pattern\n",
    "    Args:\n",
    "        lst (list): the list of website seperated content \n",
    "        pattern (rgex): the pattern we don't want \n",
    "    Return:\n",
    "        output (list): list after filter\n",
    "    '''\n",
    "    \n",
    "    output = [seq for seq in lst if not pattern.search(seq)]\n",
    "    \n",
    "    if not output:\n",
    "        return list()\n",
    "    \n",
    "    if output[0].find('】'): \n",
    "        _ = output.pop(0)\n",
    "    \n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transformSeq(seqs, seg_level):\n",
    "    '''filter the line existed Unwatned pattern, and seperate the char with \"space\"\n",
    "    Args:\n",
    "        seqs (list): list from website \n",
    "        seg_level: which lm-level ('word' OR 'char)\n",
    "    Return:\n",
    "        output (str): string which have been seperated by 'space'\n",
    "    '''\n",
    "    output = list()\n",
    "    if seg_level == 'word':\n",
    "        for seq in seqs:\n",
    "            segs = jieba.cut(seq)\n",
    "            output.append(' '.join(segs))            \n",
    "    elif seg_level == 'char':\n",
    "        for seq in seqs:\n",
    "            output.append(' '.join(seq))\n",
    "    return ' '.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def runSinica(inputfile, outputfile):\n",
    "    with open(inputfile, 'r', encoding='utf8') as fp, \\\n",
    "        open(outputfile, 'w',encoding='utf8') as wp:\n",
    "            \n",
    "        for line in fp:        \n",
    "            lst = line.strip().split()\n",
    "            item = [i.split('|')[0] for i in lst]\n",
    "            seq = ' '.join(item)\n",
    "\n",
    "            wp.write('{}\\n'.format(seq))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean ./tmp.txt\n",
      "/home/kiwi/udn_data/Files/20160618/TEXT\n",
      "記者許家瑜\n",
      "暴雨澆不熄富福里居民對「街友勸離」專案的執著，離時間還有半個鐘頭，守望相助隊副隊長謝文興抵達康定路派出所看到記者不斷強調「為了守護里民的權益\n",
      "「今天街友一定很少下雨天應該很快結束巡邏」簽到後穿上反光背心鴨舌帽口哨、拿手電筒或閃光指揮棒握拳高「街友離開、地方繁榮就來」出發時雨恰好也停了。\n",
      "警民六人穿梭潮濕巷道中，街友是否路邊。出發不到五分鐘，洪傳雄發現穿橘色外套的街友坐在陰暗台階上，腳邊放著一個大塑膠袋「阿伯你都沒洗澡身上都臭烘烘」隊員拿著閃光棒蹲低靠近，酸臭汗味撲鼻而來。\n",
      "「你一定要洗澡，可以去梧州街不要在這邊睡覺不要等我們走後再回來唷！」可以去中和收容中心，有吃睡你臭烘烘沒人要跟你睡一起」。\n",
      "三角公園，看到一對年輕情侶坐有感而發說「若是被街友霸佔，公園就是死掉了」曾有外地遊客看到街友打赤膊躺在公園內，嚇得不敢靠近。走沒幾步路，大家木質座椅上紙箱飯盒「有些街友吃便當只吃雞腿、排骨，其他隨便亂丟造成髒亂。\n",
      "大夥邊說邊走來到寺前公園，路邊變電箱圍籬內的街友「請將家當一併帶走」一百五十公分高的圍籬掩不住街友憤怒情緒，他隨手將行李、黑色後背包扔到另一頭，鐵條響起「噹噹」兩聲。\n",
      "洪傳雄靠著圍籬問街友，「你真的沒地方住嗎？別人」沒說完「如果我們角色對換你會怎麼樣」。為什麼不去遊民收容中心？很舒適，「那是真正需要的人去住」。\n",
      "隊員好奇街友為何不去找工作，他突然憤怒大吼「我也想找工作啊，你又怎麼知道我的苦衷在哪不要趕人趕到走投無路」眼看街友情緒越來越激動，勸離小組沒再多問，下個勸離點。\n",
      "兩年邁街友倒臥門前熟睡，隊員手電筒光線落在他們身上，謝文興高音量說：「這裡有貼禁止睡覺標示，阿伯快起來！」其中一名老翁坐起身長嘆一口氣，抓著殘障坡道手把撐起身子，口中念念有詞「才剛剛躺下」，拄著雨傘緩步離去。\n",
      "另名趙姓街友不理會，頭藏被子動也不動，但還是配合起身，邊收拾行李邊抗議「這邊睡了近三十年，從沒人趕過，這幾天突然要檢查要離開。」捲草蓆夾在腋下轉身尋覓另一處棲身之所。\n",
      "守望相助隊勸離趙姓街友後，為期八天的勸離行動告一段落，大家\n",
      "\n",
      "記 者 許 家 瑜 \n",
      " 暴 雨 澆 不 熄 富 福 里 居 民 對 「 街 友 勸 離 」 專 案 的 執 著 ， 離 時 間 還 有 半 個 鐘 頭 ， 守 望 相 助 隊 副 隊 長 謝 文 興 抵 達 康 定 路 派 出 所 看 到 記 者 不 斷 強 調 「 為 了 守 護 里 民 的 權 益 \n",
      " 「 今 天 街 友 一 定 很 少 下 雨 天 應 該 很 快 結 束 巡 邏 」 簽 到 後 穿 上 反 光 背 心 鴨 舌 帽 口 哨 、 拿 手 電 筒 或 閃 光 指 揮 棒 握 拳 高 「 街 友 離 開 、 地 方 繁 榮 就 來 」 出 發 時 雨 恰 好 也 停 了 。 \n",
      " 警 民 六 人 穿 梭 潮 濕 巷 道 中 ， 街 友 是 否 路 邊 。 出 發 不 到 五 分 鐘 ， 洪 傳 雄 發 現 穿 橘 色 外 套 的 街 友 坐 在 陰 暗 台 階 上 ， 腳 邊 放 著 一 個 大 塑 膠 袋 「 阿 伯 你 都 沒 洗 澡 身 上 都 臭 烘 烘 」 隊 員 拿 著 閃 光 棒 蹲 低 靠 近 ， 酸 臭 汗 味 撲 鼻 而 來 。 \n",
      " 「 你 一 定 要 洗 澡 ， 可 以 去 梧 州 街 不 要 在 這 邊 睡 覺 不 要 等 我 們 走 後 再 回 來 唷 ！ 」 可 以 去 中 和 收 容 中 心 ， 有 吃 睡 你 臭 烘 烘 沒 人 要 跟 你 睡 一 起 」 。 \n",
      " 三 角 公 園 ， 看 到 一 對 年 輕 情 侶 坐 有 感 而 發 說 「 若 是 被 街 友 霸 佔 ， 公 園 就 是 死 掉 了 」 曾 有 外 地 遊 客 看 到 街 友 打 赤 膊 躺 在 公 園 內 ， 嚇 得 不 敢 靠 近 。 走 沒 幾 步 路 ， 大 家 木 質 座 椅 上 紙 箱 飯 盒 「 有 些 街 友 吃 便 當 只 吃 雞 腿 、 排 骨 ， 其 他 隨 便 亂 丟 造 成 髒 亂 。 \n",
      " 大 夥 邊 說 邊 走 來 到 寺 前 公 園 ， 路 邊 變 電 箱 圍 籬 內 的 街 友 「 請 將 家 當 一 併 帶 走 」 一 百 五 十 公 分 高 的 圍 籬 掩 不 住 街 友 憤 怒 情 緒 ， 他 隨 手 將 行 李 、 黑 色 後 背 包 扔 到 另 一 頭 ， 鐵 條 響 起 「 噹 噹 」 兩 聲 。 \n",
      " 洪 傳 雄 靠 著 圍 籬 問 街 友 ， 「 你 真 的 沒 地 方 住 嗎 ？ 別 人 」 沒 說 完 「 如 果 我 們 角 色 對 換 你 會 怎 麼 樣 」 。 為 什 麼 不 去 遊 民 收 容 中 心 ？ 很 舒 適 ， 「 那 是 真 正 需 要 的 人 去 住 」 。 \n",
      " 隊 員 好 奇 街 友 為 何 不 去 找 工 作 ， 他 突 然 憤 怒 大 吼 「 我 也 想 找 工 作 啊 ， 你 又 怎 麼 知 道 我 的 苦 衷 在 哪 不 要 趕 人 趕 到 走 投 無 路 」 眼 看 街 友 情 緒 越 來 越 激 動 ， 勸 離 小 組 沒 再 多 問 ， 下 個 勸 離 點 。 \n",
      " 兩 年 邁 街 友 倒 臥 門 前 熟 睡 ， 隊 員 手 電 筒 光 線 落 在 他 們 身 上 ， 謝 文 興 高 音 量 說 ： 「 這 裡 有 貼 禁 止 睡 覺 標 示 ， 阿 伯 快 起 來 ！ 」 其 中 一 名 老 翁 坐 起 身 長 嘆 一 口 氣 ， 抓 著 殘 障 坡 道 手 把 撐 起 身 子 ， 口 中 念 念 有 詞 「 才 剛 剛 躺 下 」 ， 拄 著 雨 傘 緩 步 離 去 。 \n",
      " 另 名 趙 姓 街 友 不 理 會 ， 頭 藏 被 子 動 也 不 動 ， 但 還 是 配 合 起 身 ， 邊 收 拾 行 李 邊 抗 議 「 這 邊 睡 了 近 三 十 年 ， 從 沒 人 趕 過 ， 這 幾 天 突 然 要 檢 查 要 離 開 。 」 捲 草 蓆 夾 在 腋 下 轉 身 尋 覓 另 一 處 棲 身 之 所 。 \n",
      " 守 望 相 助 隊 勸 離 趙 姓 街 友 後 ， 為 期 八 天 的 勸 離 行 動 告 一 段 落 ， 大 家 \n",
      "\n",
      "網球協會今天收到國際網總（ITF）通知，盧彥勳以受傷前的保護排名世界第79取得奧運男單參賽資格，跟進謝淑薇、詹詠然、詹皓晴的行列，確定台灣網將將有1男3女出征里約奧運。\n",
      "本屆奧運網球參賽資格以法網後的世界排名結算，ITF於上周五發函通知，謝淑薇取得女單、詹詠然和詹皓晴取得女雙參賽資格，盧彥勳則因年初受傷跳過澳網，排名以些微差距擦身而過。\n",
      "但網協今天收到通知，盧彥勳以受傷前的保護排名取得資格，這將是他生涯第四度出征奧運，2004年雅典奧運和2012倫敦奧運都止步首輪，2008年北京奧運首輪擊敗英國名將墨瑞（Andy Murray）寫下代表作，最終闖進16強。\n",
      "台灣收下3席里約奧運網球參賽資格，也追平上屆席次，中華隊在2012年共派出男單盧彥勳、女單謝淑薇和女雙謝淑薇／莊佳容出征倫敦奧運，以謝莊配在女雙闖進8強成績最佳。此外，網協也報名謝淑薇與莊佳容搭檔女雙，但能否排入籤表還是未知數。\n",
      "盧彥勳本周出征在英國中部舉辦的伊爾克利挑戰賽，原訂昨晚進行的8強賽因雨取消，今天晚間再戰，對手為阿根廷選手歐利佛（Renzo Olivo），若順利晉級將面臨一日兩戰。\n",
      "\n",
      "網 球 協 會 今 天 收 到 國 際 網 總 （ I T F ） 通 知 ， 盧 彥 勳 以 受 傷 前 的 保 護 排 名 世 界 第 7 9 取 得 奧 運 男 單 參 賽 資 格 ， 跟 進 謝 淑 薇 、 詹 詠 然 、 詹 皓 晴 的 行 列 ， 確 定 台 灣 網 將 將 有 1 男 3 女 出 征 里 約 奧 運 。 \n",
      " 本 屆 奧 運 網 球 參 賽 資 格 以 法 網 後 的 世 界 排 名 結 算 ， I T F 於 上 周 五 發 函 通 知 ， 謝 淑 薇 取 得 女 單 、 詹 詠 然 和 詹 皓 晴 取 得 女 雙 參 賽 資 格 ， 盧 彥 勳 則 因 年 初 受 傷 跳 過 澳 網 ， 排 名 以 些 微 差 距 擦 身 而 過 。 \n",
      " 但 網 協 今 天 收 到 通 知 ， 盧 彥 勳 以 受 傷 前 的 保 護 排 名 取 得 資 格 ， 這 將 是 他 生 涯 第 四 度 出 征 奧 運 ， 2 0 0 4 年 雅 典 奧 運 和 2 0 1 2 倫 敦 奧 運 都 止 步 首 輪 ， 2 0 0 8 年 北 京 奧 運 首 輪 擊 敗 英 國 名 將 墨 瑞 （ A n d y   M u r r a y ） 寫 下 代 表 作 ， 最 終 闖 進 1 6 強 。 \n",
      " 台 灣 收 下 3 席 里 約 奧 運 網 球 參 賽 資 格 ， 也 追 平 上 屆 席 次 ， 中 華 隊 在 2 0 1 2 年 共 派 出 男 單 盧 彥 勳 、 女 單 謝 淑 薇 和 女 雙 謝 淑 薇 ／ 莊 佳 容 出 征 倫 敦 奧 運 ， 以 謝 莊 配 在 女 雙 闖 進 8 強 成 績 最 佳 。 此 外 ， 網 協 也 報 名 謝 淑 薇 與 莊 佳 容 搭 檔 女 雙 ， 但 能 否 排 入 籤 表 還 是 未 知 數 。 \n",
      " 盧 彥 勳 本 周 出 征 在 英 國 中 部 舉 辦 的 伊 爾 克 利 挑 戰 賽 ， 原 訂 昨 晚 進 行 的 8 強 賽 因 雨 取 消 ， 今 天 晚 間 再 戰 ， 對 手 為 阿 根 廷 選 手 歐 利 佛 （ R e n z o   O l i v o ） ， 若 順 利 晉 級 將 面 臨 一 日 兩 戰 。 \n",
      "\n",
      "\n",
      "\n",
      "HF3F2601.CAP [EF] \r\n",
      "\r\n",
      "06/18/16  00:45:36\r\n",
      "\r\n",
      "3D列印自駕迷你巴士  美國展示\r\n",
      "\r\n",
      "（中央社美國國家港灣17日綜合外電報導）自駕車新創\r\n",
      "企業Local Motors與IBM聯手推出名為Olli的自駕迷你\r\n",
      "巴士，搭配IBM超級電腦華生（Watson），如今已做好\r\n",
      "上路準備。\r\n",
      "\r\n",
      "    總部設在亞利桑那州的Local Motors於美國首都華\r\n",
      "盛頓郊區發表3D列印的Olli，此迷你巴士可搭載12人。\r\n",
      "\r\n",
      "    Olli的設計理念是提供隨選運輸解決方案，乘客可\r\n",
      "利用諸如Uber rides等手機app叫車。且能在「微工廠\r\n",
      "」於數小時內「列印出」所要規格的迷你巴士。\r\n",
      "\r\n",
      "    Olli未來幾個月將在馬里蘭州國家港灣（National\r\n",
      "Harbor）展示，且預期會在拉斯維加斯和邁阿密進行更\r\n",
      "多測試。此外，Local Motors也在洽談在全球各地數十\r\n",
      "個城市展開測試事宜，包括柏林、哥本哈根和坎培拉等\r\n",
      "城市。\r\n",
      "\r\n",
      "    即使谷歌（Google）和多家車廠一致認為，還要測\r\n",
      "試多年才能讓自駕車上路，但Local Motors共同創辦人\r\n",
      "及執行長羅傑斯（John Rogers）表示，一旦法規過關\r\n",
      "，這種車輛隨時可上路提供服務。1050618\n",
      "\n",
      "H F 3 F 2 6 0 1 . C A P   [ E F ]   \r",
      " \n",
      " \r",
      " \n",
      " 0 6 / 1 8 / 1 6     0 0 : 4 5 : 3 6 \r",
      " \n",
      " \r",
      " \n",
      " 3 D 列 印 自 駕 迷 你 巴 士     美 國 展 示 \r",
      " \n",
      " \r",
      " \n",
      " （ 中 央 社 美 國 國 家 港 灣 1 7 日 綜 合 外 電 報 導 ） 自 駕 車 新 創 \r",
      " \n",
      " 企 業 L o c a l   M o t o r s 與 I B M 聯 手 推 出 名 為 O l l i 的 自 駕 迷 你 \r",
      " \n",
      " 巴 士 ， 搭 配 I B M 超 級 電 腦 華 生 （ W a t s o n ） ， 如 今 已 做 好 \r",
      " \n",
      " 上 路 準 備 。 \r",
      " \n",
      " \r",
      " \n",
      "         總 部 設 在 亞 利 桑 那 州 的 L o c a l   M o t o r s 於 美 國 首 都 華 \r",
      " \n",
      " 盛 頓 郊 區 發 表 3 D 列 印 的 O l l i ， 此 迷 你 巴 士 可 搭 載 1 2 人 。 \r",
      " \n",
      " \r",
      " \n",
      "         O l l i 的 設 計 理 念 是 提 供 隨 選 運 輸 解 決 方 案 ， 乘 客 可 \r",
      " \n",
      " 利 用 諸 如 U b e r   r i d e s 等 手 機 a p p 叫 車 。 且 能 在 「 微 工 廠 \r",
      " \n",
      " 」 於 數 小 時 內 「 列 印 出 」 所 要 規 格 的 迷 你 巴 士 。 \r",
      " \n",
      " \r",
      " \n",
      "         O l l i 未 來 幾 個 月 將 在 馬 里 蘭 州 國 家 港 灣 （ N a t i o n a l \r",
      " \n",
      " H a r b o r ） 展 示 ， 且 預 期 會 在 拉 斯 維 加 斯 和 邁 阿 密 進 行 更 \r",
      " \n",
      " 多 測 試 。 此 外 ， L o c a l   M o t o r s 也 在 洽 談 在 全 球 各 地 數 十 \r",
      " \n",
      " 個 城 市 展 開 測 試 事 宜 ， 包 括 柏 林 、 哥 本 哈 根 和 坎 培 拉 等 \r",
      " \n",
      " 城 市 。 \r",
      " \n",
      " \r",
      " \n",
      "         即 使 谷 歌 （ G o o g l e ） 和 多 家 車 廠 一 致 認 為 ， 還 要 測 \r",
      " \n",
      " 試 多 年 才 能 讓 自 駕 車 上 路 ， 但 L o c a l   M o t o r s 共 同 創 辦 人 \r",
      " \n",
      " 及 執 行 長 羅 傑 斯 （ J o h n   R o g e r s ） 表 示 ， 一 旦 法 規 過 關 \r",
      " \n",
      " ， 這 種 車 輛 隨 時 可 上 路 提 供 服 務 。 1 0 5 0 6 1 8 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    ptn = re.compile('[1]')\n",
    "    par = {\n",
    "        'sep_method':'comma'\n",
    "        , 'seg_level':'char'}\n",
    "    \n",
    "#     data_root = sys.argv[1]\n",
    "#     output_file = sys.argv[2]  \n",
    "    data_root = '/home/kiwi/udn_data/Files/'\n",
    "    output_file = './tmp.txt'\n",
    "    \n",
    "    runUdnSegment(dataroot=data_root, outputfile=output_file,\n",
    "                 action=par, unwanted_ptn=ptn)\n",
    "    \n",
    "\n",
    "#     dataroot = '/home/kiwi/Documents/udn_data/Files/'\n",
    "#     runCharSegment(dataroot,outputfile,pattern)\n",
    "#     runWordSegment(dataroot,'./lm_data/seg_all.txt')\n",
    "#     inputfile = '/home/kiwi/udn_data/training/sinica.corpus.txt'\n",
    "#     runSinica(inputfile,'./lm_data/sinica_word.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
